{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip uninstall -y tensorflow_datasets\n! pip install tensorflow_datasets==4.4.0\n!pip install -U keras-efficientnet-v2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-03T10:12:56.304586Z","iopub.execute_input":"2022-04-03T10:12:56.306086Z","iopub.status.idle":"2022-04-03T10:13:16.488355Z","shell.execute_reply.started":"2022-04-03T10:12:56.306021Z","shell.execute_reply":"2022-04-03T10:13:16.487024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This notebook highly depends on https://www.kaggle.com/code/tchaye59/efficientnet-tensorflow-baseline-tpu/notebook \nfrom kaggle_datasets import KaggleDatasets\nGCS_PATH = KaggleDatasets().get_gcs_path()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:13:16.491335Z","iopub.execute_input":"2022-04-03T10:13:16.491713Z","iopub.status.idle":"2022-04-03T10:13:17.13466Z","shell.execute_reply.started":"2022-04-03T10:13:16.491667Z","shell.execute_reply":"2022-04-03T10:13:17.133863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GCS_PATH","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:13:17.135849Z","iopub.execute_input":"2022-04-03T10:13:17.13605Z","iopub.status.idle":"2022-04-03T10:13:17.142635Z","shell.execute_reply.started":"2022-04-03T10:13:17.136025Z","shell.execute_reply":"2022-04-03T10:13:17.141708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport keras_efficientnet_v2\nimport os\n\n# proj_dir = \"/kaggle/input/sorghum-id-fgvc-9/\"\n#proj_dir = \"C:/Users/Owner/Documents/dev/sorghum/\"\n\ndf = pd.read_csv(\"/kaggle/input/sorghum-divided-512x512/512_separated_train_cultivar_mapping.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:13:17.14519Z","iopub.execute_input":"2022-04-03T10:13:17.145585Z","iopub.status.idle":"2022-04-03T10:13:17.635089Z","shell.execute_reply.started":"2022-04-03T10:13:17.145541Z","shell.execute_reply":"2022-04-03T10:13:17.634035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile fgvc_dataset.py -a\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\n\n\nclass FGVCDataset(tfds.core.GeneratorBasedBuilder):\n    VERSION = tfds.core.Version('0.1.0')\n    \n    def _split_generators(self, dl_manager):\n        arr = [\n            tfds.core.SplitGenerator(name=f'train',gen_kwargs={\"split\":\"train\"}),\n            tfds.core.SplitGenerator(name=f'test',gen_kwargs={\"split\":\"test\"})\n        ]\n        return arr\n    \n    def _info(self):\n        return tfds.core.DatasetInfo(\n            builder=self,\n            description=(\"\"),\n            #disable_shuffling=True,\n            features=tfds.features.FeaturesDict({\n                \"img\": tfds.features.Image(encoding_format='jpeg'),#dtype=tf.uint8,shape=(self.WIDTH,self.HEIGHT,3),\n                \"name\": tfds.features.Tensor(dtype=tf.string,shape=()),\n                \"cultivar\": tfds.features.Tensor(dtype=tf.string,shape=()),\n                \"target\": tfds.features.Tensor(dtype=tf.int32,shape=()),\n            }),\n        )\n    \n    def _generate_examples(self,**args):\n        print(args)\n        split = args[\"split\"]\n        \n        if split == 'train':\n            for i in range(len(self.train_df)):\n                row = self.train_df.iloc[i]\n                img = row.fullpath\n                yield i, {\n                    'img':img,\n                    'cultivar':row.cultivar,\n                    'name':row.image,\n                    'target':row.target,\n                }\n                \n        if split == 'test':\n            for i in range(len(self.test_df)):\n                row = self.test_df.iloc[i]\n                img = row.fullpath\n                yield i, {\n                    'img':img,\n                    'name':row.image,\n                    'cultivar':'',\n                    'target':-1,\n                }","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:13:17.636581Z","iopub.execute_input":"2022-04-03T10:13:17.636903Z","iopub.status.idle":"2022-04-03T10:13:17.644632Z","shell.execute_reply.started":"2022-04-03T10:13:17.63687Z","shell.execute_reply":"2022-04-03T10:13:17.643711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def auto_select_accelerator():\n    TPU_DETECTED = False\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n        TPU_DETECTED = True\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n\n    return strategy, TPU_DETECTED\n\nstrategy, IS_TPU_ENABLE = auto_select_accelerator()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:13:17.646098Z","iopub.execute_input":"2022-04-03T10:13:17.646323Z","iopub.status.idle":"2022-04-03T10:13:24.671497Z","shell.execute_reply.started":"2022-04-03T10:13:17.646292Z","shell.execute_reply":"2022-04-03T10:13:24.670798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 128\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nSHUFFLE_SIZE = 20000\nWIDTH = 512\nHEIGHT = 512\nEPOCHS = 20\nmodel_name = \"sep_512_effnet.h5\"\n\npaths = df[\"fullpath\"]\nlabels_str = df[\"cultivar\"]\nimage_count = len(paths)\nlabel_to_index = dict((name, index) for index,name in enumerate(labels_str.unique()))\nlabels_idx = labels_str.map(lambda x: label_to_index[x])","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:13:24.673996Z","iopub.execute_input":"2022-04-03T10:13:24.674313Z","iopub.status.idle":"2022-04-03T10:13:24.755187Z","shell.execute_reply.started":"2022-04-03T10:13:24.674279Z","shell.execute_reply":"2022-04-03T10:13:24.754281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fgvc_dataset import FGVCDataset\n\ndata_dir= GCS_PATH\nbuilder = FGVCDataset(data_dir=data_dir)\nbuilder.download_and_prepare()\ntrain_ds = builder.as_dataset()['train']\ntest_ds = builder.as_dataset()['test']","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:13:24.756715Z","iopub.execute_input":"2022-04-03T10:13:24.75699Z","iopub.status.idle":"2022-04-03T10:13:25.884848Z","shell.execute_reply.started":"2022-04-03T10:13:24.75696Z","shell.execute_reply":"2022-04-03T10:13:25.883913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_augmentation():\n    return tf.keras.Sequential([\n        tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor=0.05,width_factor=0.05),\n#         tf.keras.layers.experimental.preprocessing.RandomCrop(height=HEIGHT, width=WIDTH),\n        tf.keras.layers.experimental.preprocessing.RandomContrast(0.2),\n        tf.keras.layers.experimental.preprocessing.RandomFlip(),\n        tf.keras.layers.experimental.preprocessing.RandomRotation(0.3),\n        tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.3,width_factor=0.3),\n    ])\ndata_aug = data_augmentation()\n\ndef load_train_image(data):\n    img = data['img']\n    cultivar = data['cultivar']\n    name = data['name']\n    target = data['target']\n    # Resize image\n    img = tf.image.resize(img,(WIDTH, HEIGHT),)\n\n    return img,target\n\ndef load_test_image(data):\n    img = data['img']\n    name = data['name']\n    # Resize image\n    img = tf.image.resize(img,(WIDTH, HEIGHT),)\n#     img = tf.image.random_crop(value=img,size=(WIDTH, HEIGHT, 3))\n#     img = resize_with_crop_or_pad(img, WIDTH, HEIGHT) \n#     img = tf.keras.applications.efficientnet.preprocess_input(img)\n    return img,name\n\ndef prepare_train_dataset(train_ds):\n    steps = len(train_ds)//BATCH_SIZE\n    train_ds = train_ds.repeat().shuffle(SHUFFLE_SIZE).map(load_train_image,num_parallel_calls=AUTOTUNE)\n    train_ds = train_ds.batch(BATCH_SIZE).map(lambda x,y:(data_aug(x),y),num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n    return steps,train_ds\n\ndef prepare_submission_dataset(ds):\n    ds = ds.map(load_test_image,num_parallel_calls=AUTOTUNE)\n    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:56:22.400084Z","iopub.execute_input":"2022-04-03T13:56:22.400477Z","iopub.status.idle":"2022-04-03T13:56:22.445623Z","shell.execute_reply.started":"2022-04-03T13:56:22.400437Z","shell.execute_reply":"2022-04-03T13:56:22.444647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(steps):\n    basemodel = keras_efficientnet_v2.EfficientNetV2XL(input_shape=(WIDTH, HEIGHT, 3), drop_connect_rate=0.2, num_classes=0, include_preprocessing=True, pretrained=\"imagenet21k-ft1k\")\n    basemodel.trainable = True\n    \n    image_input = tf.keras.layers.Input(shape=(WIDTH,HEIGHT,3))\n    out = basemodel(image_input)\n    out = tf.keras.layers.GlobalAveragePooling2D()(out)\n    out = tf.keras.layers.Dropout(0.3)(out)\n    out = tf.keras.layers.Dense(len(label_to_index), activation=\"softmax\")(out)\n\n    model = tf.keras.Model(image_input, out)\n\n    model.compile(optimizer=tf.keras.optimizers.Adam(), \n                  loss='sparse_categorical_crossentropy',\n                  metrics=[\"accuracy\"],\n                  steps_per_execution=steps)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:13:25.932915Z","iopub.execute_input":"2022-04-03T10:13:25.933144Z","iopub.status.idle":"2022-04-03T10:13:25.941148Z","shell.execute_reply.started":"2022-04-03T10:13:25.933108Z","shell.execute_reply":"2022-04-03T10:13:25.940009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if IS_TPU_ENABLE:\n    with strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n        model = create_model(32)\nelse:\n    model = create_model(None)\n        \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:13:25.942204Z","iopub.execute_input":"2022-04-03T10:13:25.94277Z","iopub.status.idle":"2022-04-03T10:14:28.172504Z","shell.execute_reply.started":"2022-04-03T10:13:25.942738Z","shell.execute_reply":"2022-04-03T10:14:28.171625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy',mode='max', patience=20)\n    ckp_callback = tf.keras.callbacks.ModelCheckpoint(\n                                                filepath=f'model.h5',\n                                                save_weights_only=True,\n                                                monitor='accuracy',\n                                                mode='max',\n                                                options=tf.train.CheckpointOptions(experimental_io_device='/job:localhost'),\n                                                save_best_only=True)\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy',mode='max',factor=0.2,patience=3, min_lr=1e-5)\n    callbacks=[callback,ckp_callback,reduce_lr]\n    \n    steps_per_epoch,ds =  prepare_train_dataset(train_ds)\n\n    history = model.fit(ds,\n                        steps_per_epoch=steps_per_epoch,\n                        epochs=10,\n                        callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:03:55.561776Z","iopub.execute_input":"2022-04-03T14:03:55.56222Z","iopub.status.idle":"2022-04-03T15:32:37.803572Z","shell.execute_reply.started":"2022-04-03T14:03:55.56218Z","shell.execute_reply":"2022-04-03T15:32:37.800755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"sep_512_effnet_30.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T15:33:58.436315Z","iopub.execute_input":"2022-04-03T15:33:58.437122Z","iopub.status.idle":"2022-04-03T15:34:26.897738Z","shell.execute_reply.started":"2022-04-03T15:33:58.43706Z","shell.execute_reply":"2022-04-03T15:34:26.896609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(x):\n    return model(x,training=False)\n@tf.function\ndef dist_predict(dist_inputs):\n    res = strategy.run(predict, args=(dist_inputs,))\n    return res","metadata":{"execution":{"iopub.status.busy":"2022-04-03T13:56:04.581728Z","iopub.execute_input":"2022-04-03T13:56:04.582095Z","iopub.status.idle":"2022-04-03T13:56:04.883986Z","shell.execute_reply.started":"2022-04-03T13:56:04.582057Z","shell.execute_reply":"2022-04-03T13:56:04.883013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm \nwith strategy.scope():\n    ds = prepare_submission_dataset(test_ds)\n    dist_ds = strategy.experimental_distribute_dataset(ds)\n    \n    all_names = []\n    all_targets = []\n    for img,names in tqdm(dist_ds):\n        preds = dist_predict(img)\n#         preds = tf.concat(preds.values,axis=0)\n        preds = np.concatenate(preds.values ,axis=0) \n#         names = tf.concat(names.values,axis=0)\n        names = np.concatenate(names.values ,axis=0) \n#         preds = preds.numpy()\n#         names = names.numpy()\n        all_targets.extend(list(preds))\n        all_names.extend([s.decode('ascii') for s in names])","metadata":{"execution":{"iopub.status.busy":"2022-04-03T15:34:26.901429Z","iopub.execute_input":"2022-04-03T15:34:26.901885Z","iopub.status.idle":"2022-04-03T15:37:51.849161Z","shell.execute_reply.started":"2022-04-03T15:34:26.901836Z","shell.execute_reply":"2022-04-03T15:37:51.848208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([pd.Series(all_names, name=\"sep_images\"), pd.DataFrame(all_targets, columns=label_to_index.keys())], axis=1)\ndf","metadata":{"execution":{"iopub.status.busy":"2022-04-03T15:40:05.095686Z","iopub.execute_input":"2022-04-03T15:40:05.096431Z","iopub.status.idle":"2022-04-03T15:40:12.199894Z","shell.execute_reply.started":"2022-04-03T15:40:05.096378Z","shell.execute_reply":"2022-04-03T15:40:12.199059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv(\"20220403_512_preds_30epoch.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T15:40:21.781123Z","iopub.execute_input":"2022-04-03T15:40:21.781412Z","iopub.status.idle":"2022-04-03T15:40:37.832423Z","shell.execute_reply.started":"2022-04-03T15:40:21.781384Z","shell.execute_reply":"2022-04-03T15:40:37.831724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"filename_org\"] = df['sep_images'].str.extract(r'([0-9]+_)', expand=False).str[:-1] + \".png\"\nsubmission = df.groupby('filename_org').sum()\nsubmission.idxmax(axis=1).rename({\"filename_org\": \"filename\", \"0\":\"cultivar\"}).to_csv(\"submission_512_30epochs_20220403.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T15:40:37.833839Z","iopub.execute_input":"2022-04-03T15:40:37.834193Z","iopub.status.idle":"2022-04-03T15:40:38.353936Z","shell.execute_reply.started":"2022-04-03T15:40:37.834156Z","shell.execute_reply":"2022-04-03T15:40:38.352726Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
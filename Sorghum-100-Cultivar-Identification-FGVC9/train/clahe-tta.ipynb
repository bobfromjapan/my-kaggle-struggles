{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip uninstall -y tensorflow_datasets\n! pip install tensorflow_datasets==4.4.0\n! pip install keras-efficientnet-v2\n! pip install tensorflow_addons","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-29T23:56:33.391793Z","iopub.execute_input":"2022-04-29T23:56:33.392922Z","iopub.status.idle":"2022-04-29T23:57:04.23467Z","shell.execute_reply.started":"2022-04-29T23:56:33.392784Z","shell.execute_reply":"2022-04-29T23:57:04.233119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This notebook highly depends on https://www.kaggle.com/code/tchaye59/efficientnet-tensorflow-baseline-tpu/notebook \nfrom kaggle_datasets import KaggleDatasets\nGCS_PATH = KaggleDatasets().get_gcs_path(\"fgvc9-dataset-clahe-256x256\")","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:57:04.238506Z","iopub.execute_input":"2022-04-29T23:57:04.239176Z","iopub.status.idle":"2022-04-29T23:57:04.64749Z","shell.execute_reply.started":"2022-04-29T23:57:04.239128Z","shell.execute_reply":"2022-04-29T23:57:04.646384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GCS_PATH","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:57:04.648825Z","iopub.execute_input":"2022-04-29T23:57:04.649124Z","iopub.status.idle":"2022-04-29T23:57:04.657977Z","shell.execute_reply.started":"2022-04-29T23:57:04.649092Z","shell.execute_reply":"2022-04-29T23:57:04.656995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport os\nimport keras_efficientnet_v2\n\n# proj_dir = \"/kaggle/input/sorghum-id-fgvc-9/\"\n#proj_dir = \"C:/Users/Owner/Documents/dev/sorghum/\"\n\ndf = pd.read_csv(\"../input/fgvc9-dataset-clahe-256x256/clahe_train_cultivar_mapping.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:57:04.660379Z","iopub.execute_input":"2022-04-29T23:57:04.660886Z","iopub.status.idle":"2022-04-29T23:57:11.272409Z","shell.execute_reply.started":"2022-04-29T23:57:04.660844Z","shell.execute_reply":"2022-04-29T23:57:11.27159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile fgvc_dataset.py\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\n\n\nclass FGVCDataset(tfds.core.GeneratorBasedBuilder):\n    VERSION = tfds.core.Version('0.1.0')\n    \n    def _split_generators(self, dl_manager):\n        arr = [\n            tfds.core.SplitGenerator(name=f'train',gen_kwargs={\"split\":\"train\"}),\n            tfds.core.SplitGenerator(name=f'test',gen_kwargs={\"split\":\"test\"})\n        ]\n        return arr\n    \n    def _info(self):\n        return tfds.core.DatasetInfo(\n            builder=self,\n            description=(\"\"),\n            #disable_shuffling=True,\n            features=tfds.features.FeaturesDict({\n                \"img\": tfds.features.Image(encoding_format='jpeg'),#dtype=tf.uint8,shape=(self.WIDTH,self.HEIGHT,3),\n                \"name\": tfds.features.Tensor(dtype=tf.string,shape=()),\n                \"cultivar\": tfds.features.Tensor(dtype=tf.string,shape=()),\n                \"target\": tfds.features.Tensor(dtype=tf.int32,shape=()),\n            }),\n        )\n    \n    def _generate_examples(self,**args):\n        print(args)\n        split = args[\"split\"]\n        \n        if split == 'train':\n            for i in range(len(self.train_df)):\n                row = self.train_df.iloc[i]\n                img = row.fullpath\n                yield i, {\n                    'img':img,\n                    'cultivar':row.cultivar,\n                    'name':row.image,\n                    'target':row.target,\n                }\n                \n        if split == 'test':\n            for i in range(len(self.test_df)):\n                row = self.test_df.iloc[i]\n                img = row.fullpath\n                yield i, {\n                    'img':img,\n                    'name':row.image,\n                    'cultivar':'',\n                    'target':-1,\n                }","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:57:11.273867Z","iopub.execute_input":"2022-04-29T23:57:11.274316Z","iopub.status.idle":"2022-04-29T23:57:11.282087Z","shell.execute_reply.started":"2022-04-29T23:57:11.274284Z","shell.execute_reply":"2022-04-29T23:57:11.281103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def auto_select_accelerator():\n    TPU_DETECTED = False\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n        TPU_DETECTED = True\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n\n    return strategy, TPU_DETECTED\n\nstrategy, IS_TPU_ENABLE = auto_select_accelerator()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:57:11.283617Z","iopub.execute_input":"2022-04-29T23:57:11.283832Z","iopub.status.idle":"2022-04-29T23:57:16.41338Z","shell.execute_reply.started":"2022-04-29T23:57:11.283808Z","shell.execute_reply":"2022-04-29T23:57:16.412448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 1024\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nSHUFFLE_SIZE = 200000\nWIDTH = 256\nHEIGHT = 256\nEPOCHS = 30\nMAGNITUDE = 5\n\nmodel_name = \"/kaggle/working/sep_256_effnetv2\"\n\npaths = df[\"fullpath\"]\nlabels_str = df[\"cultivar\"]\nimage_count = len(paths)\nlabel_to_index = dict((name, index) for index,name in enumerate(labels_str.unique()))\nlabels_idx = labels_str.map(lambda x: label_to_index[x])","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:57:16.414958Z","iopub.execute_input":"2022-04-29T23:57:16.415247Z","iopub.status.idle":"2022-04-29T23:57:16.449483Z","shell.execute_reply.started":"2022-04-29T23:57:16.415214Z","shell.execute_reply":"2022-04-29T23:57:16.448475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fgvc_dataset import FGVCDataset\n\ndata_dir= GCS_PATH\nbuilder = FGVCDataset(data_dir=data_dir)\nbuilder.download_and_prepare()\ntrain_ds = builder.as_dataset()['train']\ntest_ds = builder.as_dataset()['test']","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:57:16.451039Z","iopub.execute_input":"2022-04-29T23:57:16.451333Z","iopub.status.idle":"2022-04-29T23:57:18.241142Z","shell.execute_reply.started":"2022-04-29T23:57:16.451302Z","shell.execute_reply":"2022-04-29T23:57:18.240152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_augmentation():\n    return tf.keras.Sequential([\n        tf.keras.layers.experimental.preprocessing.RandomContrast(0.2),\n        tf.keras.layers.experimental.preprocessing.RandomFlip(),\n        tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n        tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.2, width_factor=0.2),\n    ])\ndata_aug = data_augmentation()\n\nimport matplotlib.pyplot as plt\n\nclass RandomProcessImage:\n    def __init__(self, target_shape=(300, 300), magnitude=0, keep_shape=False):\n        self.target_shape, self.magnitude, self.keep_shape = target_shape, magnitude, keep_shape\n        self.target_shape = target_shape if len(target_shape) == 2 else target_shape[:2]\n        if magnitude > 0:\n            from keras_efficientnet_v2 import augment\n\n            translate_const, cutout_const = 100, 40\n            # translate_const = int(target_shape[0] * 10 / magnitude)\n            # cutout_const = int(target_shape[0] * 40 / 224)\n            print(\">>>> RandAugment: magnitude = %d, translate_const = %d, cutout_const = %d\" % (magnitude, translate_const, cutout_const))\n            aa = augment.RandAugment(magnitude=magnitude, translate_const=translate_const, cutout_const=cutout_const)\n            aa.available_ops = [\"AutoContrast\", \"Rotate\", \"Contrast\", \"Brightness\", \"TranslateX\", \"TranslateY\", \"Cutout\"]\n            self.process = lambda img: aa.distort(img)\n        elif magnitude == 0:\n            self.process = lambda img: tf.image.random_flip_left_right(img)\n        else:\n            self.process = lambda img: img\n\n    def __call__(self, datapoint):\n        image = datapoint[\"img\"]\n        if self.keep_shape:\n            cropped_shape = tf.reduce_min(tf.keras.backend.shape(image)[:2])\n            image = tf.image.random_crop(image, (cropped_shape, cropped_shape, 3))\n\n        input_image = tf.image.resize(image, self.target_shape)\n        label = datapoint[\"target\"]\n        input_image = self.process(input_image)\n        # input_image = (tf.cast(input_image, tf.float32) - 127.5) / 128\n        return input_image, label\n\ntrain_process = RandomProcessImage((WIDTH, HEIGHT), MAGNITUDE, keep_shape=True)\n\ndef load_train_image(data):\n    img = data['img']\n    cultivar = data['cultivar']\n    name = data['name']\n    target = data['target']\n    # Resize image\n    img = tf.image.resize(img,(WIDTH, HEIGHT),)\n    return img,target\n\ndef load_test_image(data):\n    img = data['img']\n    name = data['name']\n    # Resize image\n    img = tf.image.resize(img,(WIDTH, HEIGHT),)\n#     img = tf.keras.applications.efficientnet_v2.preprocess_input(img)\n    return img,name\n\ndef prepare_train_dataset(train_ds):\n    steps = len(train_ds)//BATCH_SIZE\n#     train_ds = train_ds.repeat().shuffle(SHUFFLE_SIZE).map(load_train_image,num_parallel_calls=AUTOTUNE)\n    train_ds = train_ds.shuffle(SHUFFLE_SIZE).repeat()\n#     train_ds = train_ds.batch(BATCH_SIZE).map(lambda x,y:(data_aug(x),y),num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n    train_ds = train_ds.map(lambda x: train_process(x), num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n    return steps,train_ds\n\ndef prepare_submission_dataset(ds):\n    ds = ds.map(load_test_image,num_parallel_calls=AUTOTUNE)\n    ds = ds.batch(BATCH_SIZE*2).prefetch(AUTOTUNE)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:57:18.243196Z","iopub.execute_input":"2022-04-29T23:57:18.243525Z","iopub.status.idle":"2022-04-29T23:57:18.296699Z","shell.execute_reply.started":"2022-04-29T23:57:18.243484Z","shell.execute_reply":"2022-04-29T23:57:18.296056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(steps):\n    basemodel = keras_efficientnet_v2.EfficientNetV2M(input_shape=(WIDTH, HEIGHT, 3), drop_connect_rate=0.5, num_classes=0, include_preprocessing=True, pretrained=\"imagenet21k-ft1k\")\n    basemodel.trainable = True\n    \n    image_input = tf.keras.layers.Input(shape=(WIDTH,HEIGHT,3))\n    out = basemodel(image_input)\n    out = tf.keras.layers.GlobalAveragePooling2D()(out)\n    out = tf.keras.layers.Dropout(0.5)(out)\n    out = tf.keras.layers.Dense(len(label_to_index), activation=\"softmax\")(out)\n\n    model = tf.keras.Model(image_input, out)\n\n    model.compile(optimizer=tf.keras.optimizers.Adam(), \n                  loss='sparse_categorical_crossentropy',\n                  metrics=[\"accuracy\"],\n                  steps_per_execution=steps)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:57:18.298847Z","iopub.execute_input":"2022-04-29T23:57:18.299231Z","iopub.status.idle":"2022-04-29T23:57:18.308384Z","shell.execute_reply.started":"2022-04-29T23:57:18.299194Z","shell.execute_reply":"2022-04-29T23:57:18.307467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if IS_TPU_ENABLE:\n    with strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n        model = create_model(32)\nelse:\n    model = create_model()\n        \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:57:18.310075Z","iopub.execute_input":"2022-04-29T23:57:18.310529Z","iopub.status.idle":"2022-04-29T23:58:00.419828Z","shell.execute_reply.started":"2022-04-29T23:57:18.31048Z","shell.execute_reply":"2022-04-29T23:58:00.418846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy',mode='max', patience=20)\n    ckp_callback = tf.keras.callbacks.ModelCheckpoint(\n                                                filepath=f'model.h5',\n                                                save_weights_only=True,\n                                                monitor='accuracy',\n                                                mode='max',\n                                                options=tf.train.CheckpointOptions(experimental_io_device='/job:localhost'),\n                                                save_best_only=True)\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy',mode='max',factor=0.2,patience=3, min_lr=1e-5)\n    callbacks=[callback,ckp_callback,reduce_lr]\n    steps_per_epoch,ds =  prepare_train_dataset(train_ds)\n\n    history = model.fit(ds,\n                        steps_per_epoch=steps_per_epoch,\n                        epochs=50,\n                        callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T15:22:43.401818Z","iopub.execute_input":"2022-04-29T15:22:43.402061Z","iopub.status.idle":"2022-04-29T18:03:55.79455Z","shell.execute_reply.started":"2022-04-29T15:22:43.402032Z","shell.execute_reply":"2022-04-29T18:03:55.792133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"clahe_applied_4x4_50epochs.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-04-29T18:03:55.801287Z","iopub.execute_input":"2022-04-29T18:03:55.80166Z","iopub.status.idle":"2022-04-29T18:04:07.499317Z","shell.execute_reply.started":"2022-04-29T18:03:55.801608Z","shell.execute_reply":"2022-04-29T18:04:07.498405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(x):\n    return model(x,training=False)\n@tf.function\ndef dist_predict(dist_inputs):\n    res = strategy.run(predict, args=(dist_inputs,))\n    return res","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:58:00.421066Z","iopub.execute_input":"2022-04-29T23:58:00.421311Z","iopub.status.idle":"2022-04-29T23:58:00.427445Z","shell.execute_reply.started":"2022-04-29T23:58:00.421281Z","shell.execute_reply":"2022-04-29T23:58:00.426553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(\"../input/clahe-model-1/sep_256_clahe_dropout05_100epochs.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:58:00.429224Z","iopub.execute_input":"2022-04-29T23:58:00.42976Z","iopub.status.idle":"2022-04-29T23:58:12.043751Z","shell.execute_reply.started":"2022-04-29T23:58:00.429716Z","shell.execute_reply":"2022-04-29T23:58:12.042649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm \n\n# TTA1\nwith strategy.scope():\n    ds = prepare_submission_dataset(test_ds)\n    dist_ds = strategy.experimental_distribute_dataset(ds)\n    \n    all_names = []\n    all_targets = []\n    for img,names in tqdm(dist_ds):\n        preds = dist_predict(img)\n        preds = tf.concat(preds.values,axis=0)\n        names = tf.concat(names.values,axis=0)\n        preds = preds.numpy()\n        names = names.numpy()\n        all_targets.extend(list(preds))\n        all_names.extend([s.decode('ascii') for s in names])","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:58:12.046573Z","iopub.execute_input":"2022-04-29T23:58:12.047167Z","iopub.status.idle":"2022-04-29T23:59:38.064635Z","shell.execute_reply.started":"2022-04-29T23:58:12.047116Z","shell.execute_reply":"2022-04-29T23:59:38.063492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TTA2\ntta_aug_2 = tf.keras.Sequential([\n        tf.keras.layers.experimental.preprocessing.RandomFlip(),\n        tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n    ])\n\ndef prepare_submission_dataset(ds):\n    ds = ds.map(load_test_image,num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE*2)\n    ds = ds.map(lambda x,y:(tta_aug_2(x),y), num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n    return ds\n\nwith strategy.scope():\n    ds = prepare_submission_dataset(test_ds)\n    dist_ds = strategy.experimental_distribute_dataset(ds)\n    \n    all_names_2 = []\n    all_targets_2 = []\n    for img,names in tqdm(dist_ds):\n        preds = dist_predict(img)\n        preds = tf.concat(preds.values,axis=0)\n        names = tf.concat(names.values,axis=0)\n        preds = preds.numpy()\n        names = names.numpy()\n        all_targets_2.extend(list(preds))\n        all_names_2.extend([s.decode('ascii') for s in names])","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:59:38.066468Z","iopub.execute_input":"2022-04-29T23:59:38.066893Z","iopub.status.idle":"2022-04-30T00:02:02.260006Z","shell.execute_reply.started":"2022-04-29T23:59:38.066846Z","shell.execute_reply":"2022-04-30T00:02:02.2591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TTA3\ntta_aug_3 = tf.keras.Sequential([\n        tf.keras.layers.experimental.preprocessing.RandomFlip(),\n        tf.keras.layers.experimental.preprocessing.RandomContrast(0.1),\n    ])\n\ndef prepare_submission_dataset(ds):\n    ds = ds.map(load_test_image,num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE*2)\n    ds = ds.map(lambda x,y:(tta_aug_3(x),y), num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n    return ds\n\nwith strategy.scope():\n    ds = prepare_submission_dataset(test_ds)\n    dist_ds = strategy.experimental_distribute_dataset(ds)\n    \n    all_names_3 = []\n    all_targets_3 = []\n    for img,names in tqdm(dist_ds):\n        preds = dist_predict(img)\n        preds = tf.concat(preds.values,axis=0)\n        names = tf.concat(names.values,axis=0)\n        preds = preds.numpy()\n        names = names.numpy()\n        all_targets_3.extend(list(preds))\n        all_names_3.extend([s.decode('ascii') for s in names])","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:02:02.262214Z","iopub.execute_input":"2022-04-30T00:02:02.262613Z","iopub.status.idle":"2022-04-30T00:03:45.590314Z","shell.execute_reply.started":"2022-04-30T00:02:02.262566Z","shell.execute_reply":"2022-04-30T00:03:45.589401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.concat([pd.Series(all_names, name=\"sep_images\"), pd.DataFrame(all_targets, columns=label_to_index.keys())], axis=1)\ndf2 = pd.concat([pd.Series(all_names_2, name=\"sep_images\"), pd.DataFrame(all_targets_2, columns=label_to_index.keys())], axis=1)\ndf3 = pd.concat([pd.Series(all_names_3, name=\"sep_images\"), pd.DataFrame(all_targets_3, columns=label_to_index.keys())], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:03:45.591987Z","iopub.execute_input":"2022-04-30T00:03:45.592365Z","iopub.status.idle":"2022-04-30T00:05:27.188397Z","shell.execute_reply.started":"2022-04-30T00:03:45.592296Z","shell.execute_reply":"2022-04-30T00:05:27.186711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = df1\ndf = df1 + df2 + df3\n\ndf[\"sep_images\"] = df1[\"sep_images\"]\ndf.to_csv(\"sep_256_clahe_dropout05_50epochs_tta_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:05:27.19107Z","iopub.execute_input":"2022-04-30T00:05:27.192355Z","iopub.status.idle":"2022-04-30T00:06:34.722097Z","shell.execute_reply.started":"2022-04-30T00:05:27.192265Z","shell.execute_reply":"2022-04-30T00:06:34.720978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"filename\"] = df['sep_images'].str.extract(r'([0-9]+_)', expand=False).str[:-1] + \".png\"\nsubmission = df.groupby('filename').sum()\n\npd.DataFrame(submission.idxmax(axis=1), columns=[\"cultivar\"], index=None).to_csv(\"sep_256_clahe_dropout05_50epochs_tta_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:06:34.724096Z","iopub.execute_input":"2022-04-30T00:06:34.725237Z","iopub.status.idle":"2022-04-30T00:06:36.700471Z","shell.execute_reply.started":"2022-04-30T00:06:34.72516Z","shell.execute_reply":"2022-04-30T00:06:36.699402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(pd.DataFrame(submission.idxmax(axis=1), columns=[\"cultivar\"], index=None)[\"cultivar\"].unique())","metadata":{"execution":{"iopub.status.busy":"2022-04-29T18:12:31.486914Z","iopub.execute_input":"2022-04-29T18:12:31.487274Z","iopub.status.idle":"2022-04-29T18:12:31.556158Z","shell.execute_reply.started":"2022-04-29T18:12:31.487242Z","shell.execute_reply":"2022-04-29T18:12:31.555084Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad1dc45f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.008747,
     "end_time": "2022-10-02T05:18:40.947719",
     "exception": false,
     "start_time": "2022-10-02T05:18:40.938972",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CITEseq Keras Quickstart\n",
    "\n",
    "This notebook shows how to tune and cross-validate a Keras model for the CITEseq part of the *Multimodal Single-Cell Integration* competition.\n",
    "\n",
    "It does not show the EDA - see the separate notebook [MSCI EDA which makes sense ⭐️⭐️⭐️⭐️⭐️](https://www.kaggle.com/ambrosm/msci-eda-which-makes-sense).\n",
    "\n",
    "The CITEseq predictions of the Keras model are then concatenated with the Multiome predictions of @jsmithperera's [Multiome Quickstart w/ Sparse M + tSVD = 32](https://www.kaggle.com/code/jsmithperera/multiome-quickstart-w-sparse-m-tsvd-32) to a complete submission file.\n",
    "\n",
    "## Summary\n",
    "\n",
    "The CITEseq part of the competition has sizeable datasets, when compared to the standard 16 GByte RAM of Kaggle notebooks:\n",
    "- The training input has shape 70988/*22050 (10.6 GByte).\n",
    "- The training labels have shape 70988/*140.\n",
    "- The test input has shape 48663/*22050 (4.3 GByte).\n",
    "\n",
    "Our solution strategy has five elements:\n",
    "1. **Dimensionality reduction:** To reduce the size of the 10.6 GByte input data, we project the 22050 features to a space with only 64 dimensions by applying a truncated SVD. To these 64 dimensions, we add 144 features whose names shows their importance.\n",
    "2. **The model:** The model is a sequential dense network with four hidden layers.\n",
    "3. **The loss function:** The competition is scored by the average Pearson correlation coefficient between the predictions and the ground truth. As this scoring function is differentiable, we can directly use it as loss function for a neural network. This gives neural networks an advantage in comparison to algorithms which use mean squared error as a surrogate loss. \n",
    "3. **Hyperparameter tuning with KerasTuner:** We tune the hyperparameters with [KerasTuner](https://keras.io/keras_tuner/). \n",
    "4. **Cross-validation:** Submitting unvalidated models and relying only on the public leaderboard is bad practice. The model in this notebook is fully cross-validated with a 3-fold GroupKFold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0ca64fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3dcf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Documents\\dev\\open-problem\\multiome-mlp\n"
     ]
    }
   ],
   "source": [
    "%cd C:/Users/Owner/Documents/dev/open-problem/multiome-mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73080787",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-10-02T05:18:40.966045Z",
     "iopub.status.busy": "2022-10-02T05:18:40.964979Z",
     "iopub.status.idle": "2022-10-02T05:18:49.652688Z",
     "shell.execute_reply": "2022-10-02T05:18:49.651353Z"
    },
    "papermill": {
     "duration": 8.700798,
     "end_time": "2022-10-02T05:18:49.655978",
     "exception": false,
     "start_time": "2022-10-02T05:18:40.955180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, gc, pickle, datetime, scipy.sparse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, scale, MinMaxScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import keras_tuner\n",
    "\n",
    "DATA_DIR = \"C:/Users/Owner/Documents/dev/open-problem/open-problems-multimodal/\"\n",
    "FP_CELL_METADATA = os.path.join(DATA_DIR,\"metadata.csv\")\n",
    "\n",
    "FP_CITE_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_cite_inputs.h5\")\n",
    "FP_CITE_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_cite_targets.h5\")\n",
    "FP_CITE_TEST_INPUTS = os.path.join(DATA_DIR,\"test_cite_inputs.h5\")\n",
    "\n",
    "FP_MULTIOME_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_multi_inputs.h5\")\n",
    "FP_MULTIOME_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_multi_targets.h5\")\n",
    "FP_MULTIOME_TEST_INPUTS = os.path.join(DATA_DIR,\"test_multi_inputs.h5\")\n",
    "\n",
    "FP_SUBMISSION = os.path.join(DATA_DIR,\"sample_submission.csv\")\n",
    "FP_EVALUATION_IDS = os.path.join(DATA_DIR,\"evaluation_ids.csv\")\n",
    "\n",
    "TUNE = False\n",
    "SUBMIT = True\n",
    "\n",
    "USE_SAVED_PCA = True\n",
    "\n",
    "submission_name = \"submission_multi_mlp_svd512-256_wdo.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d15ec7",
   "metadata": {
    "papermill": {
     "duration": 0.007252,
     "end_time": "2022-10-02T05:18:49.670748",
     "exception": false,
     "start_time": "2022-10-02T05:18:49.663496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A little trick to save time with pip: If the module is already installed (after a restart of the notebook, for instance), pip wastes 10 seconds by checking whether a newer version exists. We can skip this check by testing for the presence of the module in a simple if statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "539e35ad",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-10-02T05:18:49.688119Z",
     "iopub.status.busy": "2022-10-02T05:18:49.686761Z",
     "iopub.status.idle": "2022-10-02T05:19:06.804207Z",
     "shell.execute_reply": "2022-10-02T05:19:06.803199Z"
    },
    "papermill": {
     "duration": 17.129669,
     "end_time": "2022-10-02T05:19:06.807709",
     "exception": false,
     "start_time": "2022-10-02T05:18:49.678040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# If you see a warning \"Failed to establish a new connection\" running this cell,\n",
    "# go to \"Settings\" on the right hand side, \n",
    "# and turn on internet. Note, you need to be phone verified.\n",
    "# We need this library to read HDF files.\n",
    "# if not os.path.exists('/opt/conda/lib/python3.7/site-packages/tables'):\n",
    "#     !pip install --quiet tables\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35cfbd0",
   "metadata": {
    "papermill": {
     "duration": 0.007106,
     "end_time": "2022-10-02T05:19:06.823152",
     "exception": false,
     "start_time": "2022-10-02T05:19:06.816046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The scoring function\n",
    "\n",
    "This competition has a special metric: For every row, it computes the Pearson correlation between y_true and y_pred, and then all these correlation coefficients are averaged. We implement two variants of the metric: The first one is for numpy arrays, the second one for tensors - thanks to @lucasmorin for the [original tensor implementation](https://www.kaggle.com/competitions/open-problems-multimodal/discussion/347595)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b8058e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T05:19:06.840828Z",
     "iopub.status.busy": "2022-10-02T05:19:06.840348Z",
     "iopub.status.idle": "2022-10-02T05:19:06.851764Z",
     "shell.execute_reply": "2022-10-02T05:19:06.850574Z"
    },
    "papermill": {
     "duration": 0.023744,
     "end_time": "2022-10-02T05:19:06.854538",
     "exception": false,
     "start_time": "2022-10-02T05:19:06.830794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correlation_score(y_true, y_pred):\n",
    "    \"\"\"Scores the predictions according to the competition rules. \n",
    "    \n",
    "    It is assumed that the predictions are not constant.\n",
    "    \n",
    "    Returns the average of each sample's Pearson correlation coefficient\"\"\"\n",
    "    if type(y_true) == pd.DataFrame: y_true = y_true.values\n",
    "    if type(y_pred) == pd.DataFrame: y_pred = y_pred.values\n",
    "    corrsum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        corrsum += np.corrcoef(y_true[i], y_pred[i])[1, 0]\n",
    "    return corrsum / len(y_true)\n",
    "\n",
    "def negative_correlation_loss(y_true, y_pred):\n",
    "    \"\"\"Negative correlation loss function for Keras\n",
    "    \n",
    "    Precondition:\n",
    "    y_true.mean(axis=1) == 0\n",
    "    y_true.std(axis=1) == 1\n",
    "    \n",
    "    Returns:\n",
    "    -1 = perfect positive correlation\n",
    "    1 = totally negative correlation\n",
    "    \"\"\"\n",
    "    my = K.mean(tf.convert_to_tensor(y_pred), axis=1)\n",
    "    my = tf.tile(tf.expand_dims(my, axis=1), (1, y_true.shape[1]))\n",
    "    ym = y_pred - my\n",
    "    r_num = K.sum(tf.multiply(y_true, ym), axis=1)\n",
    "    r_den = tf.sqrt(K.sum(K.square(ym), axis=1) * float(y_true.shape[-1]))\n",
    "    r = tf.reduce_mean(r_num / r_den)\n",
    "    return - r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688a2749",
   "metadata": {
    "papermill": {
     "duration": 0.007031,
     "end_time": "2022-10-02T05:19:06.869083",
     "exception": false,
     "start_time": "2022-10-02T05:19:06.862052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data loading and preprocessing\n",
    "\n",
    "The metadata is used only for the `GroupKFold`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73c29484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T05:19:06.885600Z",
     "iopub.status.busy": "2022-10-02T05:19:06.885168Z",
     "iopub.status.idle": "2022-10-02T05:19:07.439994Z",
     "shell.execute_reply": "2022-10-02T05:19:07.438675Z"
    },
    "papermill": {
     "duration": 0.566235,
     "end_time": "2022-10-02T05:19:07.442631",
     "exception": false,
     "start_time": "2022-10-02T05:19:06.876396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161877, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df = pd.read_csv(FP_CELL_METADATA, index_col='cell_id')\n",
    "metadata_df = metadata_df[metadata_df.technology==\"multiome\"]\n",
    "metadata_df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c2c03bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df.head()\n",
    "meta = metadata_df[:105942]\n",
    "meta_test = metadata_df[105942:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72714930",
   "metadata": {
    "papermill": {
     "duration": 0.007295,
     "end_time": "2022-10-02T05:19:07.457595",
     "exception": false,
     "start_time": "2022-10-02T05:19:07.450300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We now define two sets of features:\n",
    "- `constant_cols` is the set of all features which are constant in the train or test datset. These columns will be discarded immediately after loading.\n",
    "- `important_cols` is the set of all features whose name matches the name of a target protein. If a gene is named 'ENSG00000114013_CD86', it should be related to a protein named 'CD86'. These features will be used for the model unchanged, that is, they don't undergo dimensionality reduction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7624570",
   "metadata": {
    "papermill": {
     "duration": 0.007302,
     "end_time": "2022-10-02T05:19:07.562801",
     "exception": false,
     "start_time": "2022-10-02T05:19:07.555499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We read train and test datasets, keep the important columns and convert the rest to sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3748e526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T05:19:07.580383Z",
     "iopub.status.busy": "2022-10-02T05:19:07.580004Z",
     "iopub.status.idle": "2022-10-02T05:22:07.646160Z",
     "shell.execute_reply": "2022-10-02T05:22:07.644510Z"
    },
    "papermill": {
     "duration": 180.081933,
     "end_time": "2022-10-02T05:22:07.652303",
     "exception": false,
     "start_time": "2022-10-02T05:19:07.570370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.9 s\n",
      "Wall time: 31.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Read train and convert to sparse matrix\n",
    "X = scipy.sparse.load_npz(\"C:/Users/Owner/Documents/dev/open-problem/multimodal-single-cell-as-sparse-matrix/train_multi_inputs_values.sparse.npz\").astype('float16', copy=False)\n",
    "\n",
    "\n",
    "# Read test and convert to sparse matrix\n",
    "Xt = scipy.sparse.load_npz(\"C:/Users/Owner/Documents/dev/open-problem/multimodal-single-cell-as-sparse-matrix/test_multi_inputs_values.sparse.npz\").astype('float16', copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5845aabe",
   "metadata": {
    "papermill": {
     "duration": 0.007601,
     "end_time": "2022-10-02T05:22:07.667933",
     "exception": false,
     "start_time": "2022-10-02T05:22:07.660332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We apply the truncated SVD to train and test together. The truncated SVD is memory-efficient. We concatenate the SVD output (64 components) with the 144 important features and get the arrays `X` and `Xt`, which will be the input to the Keras model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94d7e446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105942, 228942)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81cdb3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55935, 228942)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06c603c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T05:22:07.685649Z",
     "iopub.status.busy": "2022-10-02T05:22:07.685245Z",
     "iopub.status.idle": "2022-10-02T05:26:18.505468Z",
     "shell.execute_reply": "2022-10-02T05:26:18.503843Z"
    },
    "papermill": {
     "duration": 250.841274,
     "end_time": "2022-10-02T05:26:18.517197",
     "exception": false,
     "start_time": "2022-10-02T05:22:07.675923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of both before SVD: (161877, 228942)\n",
      "CPU times: total: 688 ms\n",
      "Wall time: 681 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Apply the singular value decomposition\n",
    "both = scipy.sparse.vstack([X, Xt])\n",
    "print(f\"Shape of both before SVD: {both.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca01fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(name, model):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16f4d0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced X shape:  (105942, 512)  0.202 GByte\n",
      "Reduced Xt shape: (55935, 512)   0.107 GByte\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if USE_SAVED_PCA:\n",
    "    svd = pickle.load(open('pca.pkl', 'rb'))\n",
    "    both = svd.transform(both)\n",
    "else:\n",
    "    svd = TruncatedSVD(n_components=512, random_state=1) # 512 is possible\n",
    "    both = svd.fit_transform(both)\n",
    "    print(f\"Shape of both after SVD:  {both.shape}\")\n",
    "    save('pca.pkl', svd)\n",
    "    \n",
    "# Hstack the svd output with the important features\n",
    "X = both[:105942]\n",
    "Xt = both[105942:]\n",
    "del both\n",
    "# X = np.hstack([X, X0])\n",
    "# Xt = np.hstack([Xt, X0t])\n",
    "print(f\"Reduced X shape:  {str(X.shape):14} {X.size*4/1024/1024/1024:2.3f} GByte\")\n",
    "print(f\"Reduced Xt shape: {str(Xt.shape):14} {Xt.size*4/1024/1024/1024:2.3f} GByte\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9575a96d",
   "metadata": {
    "papermill": {
     "duration": 0.007643,
     "end_time": "2022-10-02T05:26:18.534066",
     "exception": false,
     "start_time": "2022-10-02T05:26:18.526423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, we read the target array `Y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0378f7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T05:26:18.552052Z",
     "iopub.status.busy": "2022-10-02T05:26:18.551600Z",
     "iopub.status.idle": "2022-10-02T05:26:19.281910Z",
     "shell.execute_reply": "2022-10-02T05:26:19.280763Z"
    },
    "papermill": {
     "duration": 0.742869,
     "end_time": "2022-10-02T05:26:19.284853",
     "exception": false,
     "start_time": "2022-10-02T05:26:18.541984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Read Y\n",
    "# Y = pd.read_hdf(FP_MULTIOME_TEST_INPUTS)\n",
    "# y_columns = list(Y.columns)\n",
    "# Y = Y.values\n",
    "\n",
    "# # Normalize the targets row-wise: This doesn't change the correlations,\n",
    "# # and negative_correlation_loss depends on it\n",
    "# Y -= Y.mean(axis=1).reshape(-1, 1)\n",
    "# Y /= Y.std(axis=1).reshape(-1, 1)\n",
    "    \n",
    "# print(f\"Y shape: {str(Y.shape):14} {Y.size*4/1024/1024/1024:2.3f} GByte\")\n",
    "train_targets = scipy.sparse.load_npz(\"C:/Users/Owner/Documents/dev/open-problem/multimodal-single-cell-as-sparse-matrix/train_multi_targets_values.sparse.npz\")\n",
    "\n",
    "if USE_SAVED_PCA:\n",
    "    pca2 = pickle.load(open('pca2.pkl', 'rb'))\n",
    "    train_target = pca2.transform(train_targets)\n",
    "else:\n",
    "    pca2 = TruncatedSVD(n_components=256, random_state=42)\n",
    "    train_target = pca2.fit_transform(train_targets)\n",
    "    print(pca2.explained_variance_ratio_.sum())\n",
    "    save('pca2.pkl', pca2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5397b09",
   "metadata": {
    "papermill": {
     "duration": 0.007767,
     "end_time": "2022-10-02T05:26:19.300772",
     "exception": false,
     "start_time": "2022-10-02T05:26:19.293005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The model\n",
    "\n",
    "Our model is a sequential network consisting of a few dense layers. The hyperparameters will be tuned with KerasTuner.\n",
    "\n",
    "We use the `negative_correlation_loss` defined above as loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8078ea07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T05:26:19.318297Z",
     "iopub.status.busy": "2022-10-02T05:26:19.317861Z",
     "iopub.status.idle": "2022-10-02T05:26:20.787213Z",
     "shell.execute_reply": "2022-10-02T05:26:20.785795Z"
    },
    "papermill": {
     "duration": 1.481658,
     "end_time": "2022-10-02T05:26:20.790253",
     "exception": false,
     "start_time": "2022-10-02T05:26:19.308595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LR_START = 0.01\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "def my_model(hp, n_inputs=X.shape[1]):\n",
    "    \"\"\"Sequential neural network\n",
    "    \n",
    "    Returns a compiled instance of tensorflow.keras.models.Model.\n",
    "    \"\"\"\n",
    "    activation = 'swish'\n",
    "    reg1 = hp.Float(\"reg1\", min_value=1e-8, max_value=1e-4, sampling=\"log\")\n",
    "    reg2 = hp.Float(\"reg2\", min_value=1e-10, max_value=1e-5, sampling=\"log\")\n",
    "    \n",
    "    inputs = Input(shape=(n_inputs, ))\n",
    "    x0 = Dense(hp.Int('units1', min_value=128, max_value=384, step=64), kernel_regularizer=tf.keras.regularizers.l2(reg1),\n",
    "              activation=activation,\n",
    "             )(inputs)\n",
    "    do1 = Dropout(hp.Choice('do1', [0.1]))(x0)\n",
    "    x1 = Dense(hp.Int('units2', min_value=128, max_value=384, step=64), kernel_regularizer=tf.keras.regularizers.l2(reg1),\n",
    "              activation=activation,\n",
    "             )(do1)\n",
    "    do2 = Dropout(hp.Choice('do2', [0.1]))(x1)\n",
    "    x2 = Dense(hp.Int('units3', min_value=128, max_value=384, step=64), kernel_regularizer=tf.keras.regularizers.l2(reg1),\n",
    "              activation=activation,\n",
    "             )(do2)\n",
    "    do3 = Dropout(hp.Choice('do3', [0.1]))(x2)\n",
    "    x3 = Dense(hp.Int('units4', min_value=64, max_value=256, step=64), kernel_regularizer=tf.keras.regularizers.l2(reg1),\n",
    "              activation=activation,\n",
    "             )(do3)\n",
    "    do4 = Dropout(hp.Choice('do4', [0.1]))(x3)\n",
    "    x = Concatenate()([x0, x1, x2, x3])\n",
    "    do5 = Dropout(hp.Choice('do5', [0.2]))(x)\n",
    "    x = Dense(train_target.shape[1], kernel_regularizer=tf.keras.regularizers.l2(reg2),\n",
    "              #activation=activation,\n",
    "             )(do5)\n",
    "    regressor = Model(inputs, x)\n",
    "    regressor.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Float('lr', min_value=0.001, max_value=0.01, step=0.001)),\n",
    "                      metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "                      loss=tf.keras.losses.MeanSquaredError(),\n",
    "                     )\n",
    "   \n",
    "    return regressor\n",
    "\n",
    "display(plot_model(my_model(keras_tuner.HyperParameters()), show_layer_names=False, show_shapes=True, dpi=72))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d314be71",
   "metadata": {
    "papermill": {
     "duration": 0.008795,
     "end_time": "2022-10-02T05:26:20.808723",
     "exception": false,
     "start_time": "2022-10-02T05:26:20.799928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tuning with KerasTuner\n",
    "\n",
    "Now we let [KerasTuner](https://keras.io/keras_tuner/) optimize the hyperparameters. The tunable hyperparameters are:\n",
    "- the sizes of the hidden layers\n",
    "- the regularization factors\n",
    "\n",
    "If you want to save time, you can either set `max_trials` to a lower value or skip tuning completely and set `best_hp.values` manually. If you don't want to see all the output of the tuner, you can set `verbose` to 0 in the call to `tuner.search()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "112e4a31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T05:26:20.828608Z",
     "iopub.status.busy": "2022-10-02T05:26:20.828206Z",
     "iopub.status.idle": "2022-10-02T05:26:20.838377Z",
     "shell.execute_reply": "2022-10-02T05:26:20.837277Z"
    },
    "papermill": {
     "duration": 0.02366,
     "end_time": "2022-10-02T05:26:20.841383",
     "exception": false,
     "start_time": "2022-10-02T05:26:20.817723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if TUNE:\n",
    "    tuner = keras_tuner.BayesianOptimization(\n",
    "        my_model,\n",
    "        overwrite=True,\n",
    "        objective=keras_tuner.Objective(\"val_root_mean_squared_error\", direction=\"min\"),\n",
    "        max_trials=100,\n",
    "        directory='temp',\n",
    "        seed=1)\n",
    "    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, \n",
    "                           patience=4, verbose=0)\n",
    "    es = EarlyStopping(monitor=\"val_loss\",\n",
    "                       patience=8, \n",
    "                       verbose=0,\n",
    "                       mode=\"min\", \n",
    "                       restore_best_weights=True)\n",
    "    callbacks = [lr, es, tf.keras.callbacks.TerminateOnNaN()]\n",
    "    X_tr, X_va, y_tr, y_va = train_test_split(X, train_target, test_size=0.2, random_state=10)\n",
    "    tuner.search(X_tr, y_tr,\n",
    "                 epochs=100,\n",
    "                 validation_data=(X_va, y_va),\n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 callbacks=callbacks, verbose=2)\n",
    "    del X_tr, X_va, y_tr, y_va, lr, es, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f497b058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T05:26:20.862170Z",
     "iopub.status.busy": "2022-10-02T05:26:20.861750Z",
     "iopub.status.idle": "2022-10-02T05:26:20.867928Z",
     "shell.execute_reply": "2022-10-02T05:26:20.866813Z"
    },
    "papermill": {
     "duration": 0.018974,
     "end_time": "2022-10-02T05:26:20.870385",
     "exception": false,
     "start_time": "2022-10-02T05:26:20.851411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TUNE:\n",
    "    tuner.results_summary()\n",
    "    \n",
    "    # Table of the 10 best trials\n",
    "    display(pd.DataFrame([hp.values for hp in tuner.get_best_hyperparameters(10)]))\n",
    "    \n",
    "    # Keep the best hyperparameters\n",
    "    best_hp = tuner.get_best_hyperparameters(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b770a6ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T05:26:20.890069Z",
     "iopub.status.busy": "2022-10-02T05:26:20.889618Z",
     "iopub.status.idle": "2022-10-02T05:26:20.895840Z",
     "shell.execute_reply": "2022-10-02T05:26:20.894709Z"
    },
    "papermill": {
     "duration": 0.018886,
     "end_time": "2022-10-02T05:26:20.898276",
     "exception": false,
     "start_time": "2022-10-02T05:26:20.879390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters can be set manually\n",
    "if not TUNE:\n",
    "    best_hp = keras_tuner.HyperParameters()\n",
    "    best_hp.values = {'reg1': 0.0001,\n",
    "                      'reg2': 1.000000e-5,\n",
    "                      'units1': 128,\n",
    "                      'units2': 384,\n",
    "                      'units3': 128,\n",
    "                      'units4': 256,\n",
    "                      'do1': 0.1,\n",
    "                      'do2': 0.1,\n",
    "                      'do3': 0.1,\n",
    "                      'do4': 0.1,\n",
    "                      'do5': 0.1,\n",
    "                      'lr': 0.001,\n",
    "                     }\n",
    "    \n",
    "#     Output exceeds the size limit. Open the full output data in a text editor\n",
    "# Trial 47 Complete [00h 01m 45s]\n",
    "# val_root_mean_squared_error: 3.435828447341919\n",
    "\n",
    "# Best val_root_mean_squared_error So Far: 3.4250566959381104\n",
    "# Total elapsed time: 01h 21m 54s\n",
    "\n",
    "# Search: Running Trial #48\n",
    "\n",
    "# Value             |Best Value So Far |Hyperparameter\n",
    "# 0.0001            |0.0001            |reg1\n",
    "# 1e-05             |1e-05             |reg2\n",
    "# 128               |128               |units1\n",
    "# 0.1               |0.1               |do1\n",
    "# 384               |384               |units2\n",
    "# 0.1               |0.1               |do2\n",
    "# 128               |128               |units3\n",
    "# 0.1               |0.1               |do3\n",
    "# 256               |256               |units4\n",
    "# 0.1               |0.1               |do4\n",
    "# 0.1               |0.1               |do5\n",
    "# 0.001             |0.001             |lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70626ea0",
   "metadata": {
    "papermill": {
     "duration": 0.009056,
     "end_time": "2022-10-02T05:26:20.916326",
     "exception": false,
     "start_time": "2022-10-02T05:26:20.907270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cross-validation\n",
    "\n",
    "For cross-validation of the tuned model, we create three folds. In every fold, we train on the data of two donors and predict the third one. This scheme mimics the situation of the public leaderboard, where we train on three donors and predict the fourth one (see [EDA](https://www.kaggle.com/ambrosm/msci-eda-which-makes-sense)). \n",
    "\n",
    "The models are saved so that we can use them to compute the test predictions later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ca965a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T05:26:20.936323Z",
     "iopub.status.busy": "2022-10-02T05:26:20.935948Z",
     "iopub.status.idle": "2022-10-02T05:34:39.582799Z",
     "shell.execute_reply": "2022-10-02T05:34:39.581410Z"
    },
    "papermill": {
     "duration": 498.669766,
     "end_time": "2022-10-02T05:34:39.595133",
     "exception": false,
     "start_time": "2022-10-02T05:26:20.925367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n",
      "254/254 - 4s - loss: 39.6057 - root_mean_squared_error: 6.2866 - val_loss: 17.3611 - val_root_mean_squared_error: 4.1560 - lr: 0.0010 - 4s/epoch - 15ms/step\n",
      "Epoch 2/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n",
      "254/254 - 2s - loss: 17.1003 - root_mean_squared_error: 4.1244 - val_loss: 15.3912 - val_root_mean_squared_error: 3.9116 - lr: 0.0010 - 2s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n",
      "254/254 - 3s - loss: 15.2891 - root_mean_squared_error: 3.8984 - val_loss: 14.6773 - val_root_mean_squared_error: 3.8189 - lr: 0.0010 - 3s/epoch - 11ms/step\n",
      "Epoch 4/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n",
      "254/254 - 3s - loss: 14.4520 - root_mean_squared_error: 3.7891 - val_loss: 14.2574 - val_root_mean_squared_error: 3.7632 - lr: 0.0010 - 3s/epoch - 11ms/step\n",
      "Epoch 5/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n",
      "254/254 - 3s - loss: 13.9482 - root_mean_squared_error: 3.7216 - val_loss: 13.9723 - val_root_mean_squared_error: 3.7246 - lr: 0.0010 - 3s/epoch - 11ms/step\n",
      "Epoch 6/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n",
      "254/254 - 3s - loss: 13.5705 - root_mean_squared_error: 3.6700 - val_loss: 13.7987 - val_root_mean_squared_error: 3.7007 - lr: 0.0010 - 3s/epoch - 12ms/step\n",
      "Epoch 7/1000\n",
      "254/254 - 2s - loss: 13.2935 - root_mean_squared_error: 3.6315 - val_loss: 13.8392 - val_root_mean_squared_error: 3.7056 - lr: 0.0010 - 2s/epoch - 8ms/step\n",
      "Epoch 8/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n",
      "254/254 - 3s - loss: 13.0640 - root_mean_squared_error: 3.5992 - val_loss: 13.5695 - val_root_mean_squared_error: 3.6684 - lr: 0.0010 - 3s/epoch - 11ms/step\n",
      "Epoch 9/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n",
      "254/254 - 3s - loss: 12.8499 - root_mean_squared_error: 3.5687 - val_loss: 13.4553 - val_root_mean_squared_error: 3.6522 - lr: 0.0010 - 3s/epoch - 11ms/step\n",
      "Epoch 10/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n",
      "254/254 - 3s - loss: 12.6583 - root_mean_squared_error: 3.5411 - val_loss: 13.3993 - val_root_mean_squared_error: 3.6440 - lr: 0.0010 - 3s/epoch - 12ms/step\n",
      "Epoch 11/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n",
      "254/254 - 3s - loss: 12.4995 - root_mean_squared_error: 3.5180 - val_loss: 13.3277 - val_root_mean_squared_error: 3.6335 - lr: 0.0010 - 3s/epoch - 11ms/step\n",
      "Epoch 12/1000\n",
      "254/254 - 2s - loss: 12.3537 - root_mean_squared_error: 3.4966 - val_loss: 13.4025 - val_root_mean_squared_error: 3.6433 - lr: 0.0010 - 2s/epoch - 8ms/step\n",
      "Epoch 13/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n",
      "254/254 - 3s - loss: 12.2584 - root_mean_squared_error: 3.4824 - val_loss: 13.2722 - val_root_mean_squared_error: 3.6248 - lr: 0.0010 - 3s/epoch - 11ms/step\n",
      "Epoch 14/1000\n",
      "254/254 - 2s - loss: 12.1209 - root_mean_squared_error: 3.4621 - val_loss: 13.3045 - val_root_mean_squared_error: 3.6288 - lr: 0.0010 - 2s/epoch - 8ms/step\n",
      "Epoch 15/1000\n",
      "254/254 - 2s - loss: 12.0276 - root_mean_squared_error: 3.4481 - val_loss: 13.2835 - val_root_mean_squared_error: 3.6254 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 16/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n",
      "254/254 - 3s - loss: 11.9457 - root_mean_squared_error: 3.4357 - val_loss: 13.2282 - val_root_mean_squared_error: 3.6174 - lr: 0.0010 - 3s/epoch - 10ms/step\n",
      "Epoch 17/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n",
      "254/254 - 3s - loss: 11.8659 - root_mean_squared_error: 3.4237 - val_loss: 13.2150 - val_root_mean_squared_error: 3.6152 - lr: 0.0010 - 3s/epoch - 11ms/step\n",
      "Epoch 18/1000\n",
      "254/254 - 2s - loss: 11.7845 - root_mean_squared_error: 3.4114 - val_loss: 13.3434 - val_root_mean_squared_error: 3.6326 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 19/1000\n",
      "254/254 - 2s - loss: 11.7108 - root_mean_squared_error: 3.4002 - val_loss: 13.3155 - val_root_mean_squared_error: 3.6283 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 20/1000\n",
      "254/254 - 2s - loss: 11.6391 - root_mean_squared_error: 3.3893 - val_loss: 13.2322 - val_root_mean_squared_error: 3.6166 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 21/1000\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "254/254 - 2s - loss: 11.5828 - root_mean_squared_error: 3.3807 - val_loss: 13.3103 - val_root_mean_squared_error: 3.6271 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 22/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n",
      "254/254 - 3s - loss: 11.3843 - root_mean_squared_error: 3.3510 - val_loss: 13.1949 - val_root_mean_squared_error: 3.6110 - lr: 5.0000e-04 - 3s/epoch - 11ms/step\n",
      "Epoch 23/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n",
      "254/254 - 3s - loss: 11.3237 - root_mean_squared_error: 3.3419 - val_loss: 13.1928 - val_root_mean_squared_error: 3.6107 - lr: 5.0000e-04 - 3s/epoch - 11ms/step\n",
      "Epoch 24/1000\n",
      "254/254 - 2s - loss: 11.2814 - root_mean_squared_error: 3.3354 - val_loss: 13.2415 - val_root_mean_squared_error: 3.6173 - lr: 5.0000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 25/1000\n",
      "254/254 - 2s - loss: 11.2596 - root_mean_squared_error: 3.3321 - val_loss: 13.2836 - val_root_mean_squared_error: 3.6230 - lr: 5.0000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 26/1000\n",
      "254/254 - 2s - loss: 11.2333 - root_mean_squared_error: 3.3280 - val_loss: 13.2842 - val_root_mean_squared_error: 3.6230 - lr: 5.0000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 27/1000\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "254/254 - 2s - loss: 11.2095 - root_mean_squared_error: 3.3243 - val_loss: 13.2252 - val_root_mean_squared_error: 3.6147 - lr: 5.0000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 28/1000\n",
      "254/254 - 2s - loss: 11.0831 - root_mean_squared_error: 3.3051 - val_loss: 13.2013 - val_root_mean_squared_error: 3.6114 - lr: 2.5000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 29/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n",
      "254/254 - 3s - loss: 11.0607 - root_mean_squared_error: 3.3017 - val_loss: 13.1829 - val_root_mean_squared_error: 3.6088 - lr: 2.5000e-04 - 3s/epoch - 11ms/step\n",
      "Epoch 30/1000\n",
      "254/254 - 2s - loss: 11.0446 - root_mean_squared_error: 3.2992 - val_loss: 13.1905 - val_root_mean_squared_error: 3.6098 - lr: 2.5000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 31/1000\n",
      "254/254 - 2s - loss: 11.0363 - root_mean_squared_error: 3.2979 - val_loss: 13.2359 - val_root_mean_squared_error: 3.6160 - lr: 2.5000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 32/1000\n",
      "254/254 - 2s - loss: 11.0081 - root_mean_squared_error: 3.2936 - val_loss: 13.2123 - val_root_mean_squared_error: 3.6127 - lr: 2.5000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 33/1000\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "254/254 - 2s - loss: 11.0057 - root_mean_squared_error: 3.2932 - val_loss: 13.2067 - val_root_mean_squared_error: 3.6119 - lr: 2.5000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 34/1000\n",
      "254/254 - 2s - loss: 10.9322 - root_mean_squared_error: 3.2820 - val_loss: 13.2126 - val_root_mean_squared_error: 3.6127 - lr: 1.2500e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 35/1000\n",
      "254/254 - 2s - loss: 10.9229 - root_mean_squared_error: 3.2805 - val_loss: 13.2036 - val_root_mean_squared_error: 3.6114 - lr: 1.2500e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 36/1000\n",
      "254/254 - 2s - loss: 10.9347 - root_mean_squared_error: 3.2823 - val_loss: 13.1920 - val_root_mean_squared_error: 3.6098 - lr: 1.2500e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 37/1000\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "254/254 - 2s - loss: 10.9132 - root_mean_squared_error: 3.2790 - val_loss: 13.2204 - val_root_mean_squared_error: 3.6137 - lr: 1.2500e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 38/1000\n",
      "254/254 - 2s - loss: 10.8754 - root_mean_squared_error: 3.2732 - val_loss: 13.2235 - val_root_mean_squared_error: 3.6142 - lr: 6.2500e-05 - 2s/epoch - 7ms/step\n",
      "Epoch 39/1000\n",
      "254/254 - 2s - loss: 10.8782 - root_mean_squared_error: 3.2736 - val_loss: 13.2365 - val_root_mean_squared_error: 3.6159 - lr: 6.2500e-05 - 2s/epoch - 7ms/step\n",
      "Epoch 40/1000\n",
      "254/254 - 2s - loss: 10.8880 - root_mean_squared_error: 3.2751 - val_loss: 13.2169 - val_root_mean_squared_error: 3.6132 - lr: 6.2500e-05 - 2s/epoch - 7ms/step\n",
      "Epoch 41/1000\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "254/254 - 2s - loss: 10.8720 - root_mean_squared_error: 3.2727 - val_loss: 13.2220 - val_root_mean_squared_error: 3.6139 - lr: 6.2500e-05 - 2s/epoch - 7ms/step\n",
      "INFO:tensorflow:Assets written to: model/model_0\\assets\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Fold 0:  40 epochs, corr =  0.67102\n",
      "Epoch 1/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n",
      "286/286 - 4s - loss: 37.3639 - root_mean_squared_error: 6.1056 - val_loss: 16.5621 - val_root_mean_squared_error: 4.0586 - lr: 0.0010 - 4s/epoch - 13ms/step\n",
      "Epoch 2/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n",
      "286/286 - 3s - loss: 16.6820 - root_mean_squared_error: 4.0733 - val_loss: 15.0057 - val_root_mean_squared_error: 3.8618 - lr: 0.0010 - 3s/epoch - 10ms/step\n",
      "Epoch 3/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n",
      "286/286 - 3s - loss: 15.0471 - root_mean_squared_error: 3.8670 - val_loss: 14.3789 - val_root_mean_squared_error: 3.7794 - lr: 0.0010 - 3s/epoch - 11ms/step\n",
      "Epoch 4/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n",
      "286/286 - 3s - loss: 14.2735 - root_mean_squared_error: 3.7651 - val_loss: 13.8302 - val_root_mean_squared_error: 3.7055 - lr: 0.0010 - 3s/epoch - 11ms/step\n",
      "Epoch 5/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n",
      "286/286 - 3s - loss: 13.8158 - root_mean_squared_error: 3.7033 - val_loss: 13.6839 - val_root_mean_squared_error: 3.6852 - lr: 0.0010 - 3s/epoch - 10ms/step\n",
      "Epoch 6/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n",
      "286/286 - 3s - loss: 13.4705 - root_mean_squared_error: 3.6558 - val_loss: 13.6544 - val_root_mean_squared_error: 3.6806 - lr: 0.0010 - 3s/epoch - 11ms/step\n",
      "Epoch 7/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n",
      "286/286 - 3s - loss: 13.2134 - root_mean_squared_error: 3.6199 - val_loss: 13.2594 - val_root_mean_squared_error: 3.6260 - lr: 0.0010 - 3s/epoch - 10ms/step\n",
      "Epoch 8/1000\n",
      "286/286 - 2s - loss: 12.9571 - root_mean_squared_error: 3.5837 - val_loss: 13.3733 - val_root_mean_squared_error: 3.6410 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 9/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n",
      "286/286 - 3s - loss: 12.7558 - root_mean_squared_error: 3.5549 - val_loss: 13.2526 - val_root_mean_squared_error: 3.6238 - lr: 0.0010 - 3s/epoch - 11ms/step\n",
      "Epoch 10/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n",
      "286/286 - 3s - loss: 12.5657 - root_mean_squared_error: 3.5274 - val_loss: 13.1038 - val_root_mean_squared_error: 3.6026 - lr: 0.0010 - 3s/epoch - 11ms/step\n",
      "Epoch 11/1000\n",
      "286/286 - 2s - loss: 12.4541 - root_mean_squared_error: 3.5110 - val_loss: 13.2036 - val_root_mean_squared_error: 3.6159 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 12/1000\n",
      "286/286 - 2s - loss: 12.2984 - root_mean_squared_error: 3.4882 - val_loss: 13.2306 - val_root_mean_squared_error: 3.6191 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 13/1000\n",
      "286/286 - 2s - loss: 12.2041 - root_mean_squared_error: 3.4741 - val_loss: 13.2235 - val_root_mean_squared_error: 3.6176 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 14/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n",
      "286/286 - 3s - loss: 12.0809 - root_mean_squared_error: 3.4558 - val_loss: 12.8988 - val_root_mean_squared_error: 3.5720 - lr: 0.0010 - 3s/epoch - 10ms/step\n",
      "Epoch 15/1000\n",
      "286/286 - 2s - loss: 11.9744 - root_mean_squared_error: 3.4399 - val_loss: 13.1743 - val_root_mean_squared_error: 3.6099 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 16/1000\n",
      "286/286 - 2s - loss: 11.9063 - root_mean_squared_error: 3.4295 - val_loss: 13.1831 - val_root_mean_squared_error: 3.6107 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 17/1000\n",
      "286/286 - 2s - loss: 11.8443 - root_mean_squared_error: 3.4200 - val_loss: 13.2486 - val_root_mean_squared_error: 3.6193 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "286/286 - 2s - loss: 11.7362 - root_mean_squared_error: 3.4038 - val_loss: 13.2604 - val_root_mean_squared_error: 3.6206 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 19/1000\n",
      "286/286 - 2s - loss: 11.5315 - root_mean_squared_error: 3.3734 - val_loss: 12.9887 - val_root_mean_squared_error: 3.5828 - lr: 5.0000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 20/1000\n",
      "286/286 - 2s - loss: 11.4614 - root_mean_squared_error: 3.3629 - val_loss: 12.9853 - val_root_mean_squared_error: 3.5822 - lr: 5.0000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 21/1000\n",
      "286/286 - 2s - loss: 11.4072 - root_mean_squared_error: 3.3547 - val_loss: 13.1859 - val_root_mean_squared_error: 3.6100 - lr: 5.0000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 22/1000\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "286/286 - 2s - loss: 11.3773 - root_mean_squared_error: 3.3501 - val_loss: 12.9287 - val_root_mean_squared_error: 3.5741 - lr: 5.0000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 23/1000\n",
      "286/286 - 2s - loss: 11.2594 - root_mean_squared_error: 3.3324 - val_loss: 12.9043 - val_root_mean_squared_error: 3.5706 - lr: 2.5000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 24/1000\n",
      "286/286 - 2s - loss: 11.2272 - root_mean_squared_error: 3.3275 - val_loss: 12.9366 - val_root_mean_squared_error: 3.5751 - lr: 2.5000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 25/1000\n",
      "286/286 - 2s - loss: 11.2144 - root_mean_squared_error: 3.3255 - val_loss: 13.0009 - val_root_mean_squared_error: 3.5841 - lr: 2.5000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 26/1000\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "286/286 - 2s - loss: 11.1907 - root_mean_squared_error: 3.3219 - val_loss: 13.0193 - val_root_mean_squared_error: 3.5866 - lr: 2.5000e-04 - 2s/epoch - 7ms/step\n",
      "INFO:tensorflow:Assets written to: model/model_1\\assets\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "Fold 1:  25 epochs, corr =  0.66910\n",
      "Epoch 1/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n",
      "290/290 - 3s - loss: 35.7511 - root_mean_squared_error: 5.9721 - val_loss: 18.1689 - val_root_mean_squared_error: 4.2520 - lr: 0.0010 - 3s/epoch - 12ms/step\n",
      "Epoch 2/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n",
      "290/290 - 3s - loss: 15.9633 - root_mean_squared_error: 3.9841 - val_loss: 16.5566 - val_root_mean_squared_error: 4.0577 - lr: 0.0010 - 3s/epoch - 10ms/step\n",
      "Epoch 3/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n",
      "290/290 - 3s - loss: 14.3032 - root_mean_squared_error: 3.7697 - val_loss: 15.7996 - val_root_mean_squared_error: 3.9630 - lr: 0.0010 - 3s/epoch - 10ms/step\n",
      "Epoch 4/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n",
      "290/290 - 3s - loss: 13.5390 - root_mean_squared_error: 3.6665 - val_loss: 15.7913 - val_root_mean_squared_error: 3.9616 - lr: 0.0010 - 3s/epoch - 11ms/step\n",
      "Epoch 5/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n",
      "290/290 - 3s - loss: 13.1106 - root_mean_squared_error: 3.6072 - val_loss: 15.2806 - val_root_mean_squared_error: 3.8962 - lr: 0.0010 - 3s/epoch - 10ms/step\n",
      "Epoch 6/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n",
      "290/290 - 3s - loss: 12.7848 - root_mean_squared_error: 3.5612 - val_loss: 14.9590 - val_root_mean_squared_error: 3.8542 - lr: 0.0010 - 3s/epoch - 10ms/step\n",
      "Epoch 7/1000\n",
      "290/290 - 2s - loss: 12.5749 - root_mean_squared_error: 3.5311 - val_loss: 15.1589 - val_root_mean_squared_error: 3.8795 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 8/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n",
      "290/290 - 3s - loss: 12.3782 - root_mean_squared_error: 3.5025 - val_loss: 14.7919 - val_root_mean_squared_error: 3.8314 - lr: 0.0010 - 3s/epoch - 10ms/step\n",
      "Epoch 9/1000\n",
      "290/290 - 2s - loss: 12.1941 - root_mean_squared_error: 3.4756 - val_loss: 14.8083 - val_root_mean_squared_error: 3.8330 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 10/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n",
      "290/290 - 3s - loss: 12.0384 - root_mean_squared_error: 3.4526 - val_loss: 14.6224 - val_root_mean_squared_error: 3.8082 - lr: 0.0010 - 3s/epoch - 11ms/step\n",
      "Epoch 11/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n",
      "290/290 - 3s - loss: 11.9398 - root_mean_squared_error: 3.4377 - val_loss: 14.5405 - val_root_mean_squared_error: 3.7970 - lr: 0.0010 - 3s/epoch - 10ms/step\n",
      "Epoch 12/1000\n",
      "290/290 - 2s - loss: 11.8100 - root_mean_squared_error: 3.4183 - val_loss: 14.5646 - val_root_mean_squared_error: 3.7997 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 13/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n",
      "290/290 - 3s - loss: 11.6983 - root_mean_squared_error: 3.4015 - val_loss: 14.4951 - val_root_mean_squared_error: 3.7902 - lr: 0.0010 - 3s/epoch - 10ms/step\n",
      "Epoch 14/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n",
      "290/290 - 3s - loss: 11.5889 - root_mean_squared_error: 3.3850 - val_loss: 14.3795 - val_root_mean_squared_error: 3.7746 - lr: 0.0010 - 3s/epoch - 10ms/step\n",
      "Epoch 15/1000\n",
      "290/290 - 2s - loss: 11.5075 - root_mean_squared_error: 3.3726 - val_loss: 14.5230 - val_root_mean_squared_error: 3.7932 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 16/1000\n",
      "290/290 - 2s - loss: 11.4273 - root_mean_squared_error: 3.3603 - val_loss: 14.4746 - val_root_mean_squared_error: 3.7865 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 17/1000\n",
      "290/290 - 2s - loss: 11.3575 - root_mean_squared_error: 3.3495 - val_loss: 14.6260 - val_root_mean_squared_error: 3.8061 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "290/290 - 2s - loss: 11.3060 - root_mean_squared_error: 3.3414 - val_loss: 14.4189 - val_root_mean_squared_error: 3.7785 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 19/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n",
      "290/290 - 2s - loss: 11.0669 - root_mean_squared_error: 3.3053 - val_loss: 14.3298 - val_root_mean_squared_error: 3.7667 - lr: 5.0000e-04 - 2s/epoch - 9ms/step\n",
      "Epoch 20/1000\n",
      "290/290 - 2s - loss: 11.0063 - root_mean_squared_error: 3.2961 - val_loss: 14.3862 - val_root_mean_squared_error: 3.7741 - lr: 5.0000e-04 - 2s/epoch - 5ms/step\n",
      "Epoch 21/1000\n",
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n",
      "290/290 - 3s - loss: 10.9648 - root_mean_squared_error: 3.2896 - val_loss: 14.3035 - val_root_mean_squared_error: 3.7630 - lr: 5.0000e-04 - 3s/epoch - 10ms/step\n",
      "Epoch 22/1000\n",
      "290/290 - 2s - loss: 10.9349 - root_mean_squared_error: 3.2850 - val_loss: 14.4451 - val_root_mean_squared_error: 3.7817 - lr: 5.0000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 23/1000\n",
      "290/290 - 2s - loss: 10.9124 - root_mean_squared_error: 3.2814 - val_loss: 14.3963 - val_root_mean_squared_error: 3.7751 - lr: 5.0000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 24/1000\n",
      "290/290 - 2s - loss: 10.8932 - root_mean_squared_error: 3.2784 - val_loss: 14.4458 - val_root_mean_squared_error: 3.7815 - lr: 5.0000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 25/1000\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "290/290 - 2s - loss: 10.8473 - root_mean_squared_error: 3.2713 - val_loss: 14.4639 - val_root_mean_squared_error: 3.7838 - lr: 5.0000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 26/1000\n",
      "290/290 - 2s - loss: 10.7385 - root_mean_squared_error: 3.2545 - val_loss: 14.3073 - val_root_mean_squared_error: 3.7631 - lr: 2.5000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 27/1000\n",
      "290/290 - 2s - loss: 10.7047 - root_mean_squared_error: 3.2493 - val_loss: 14.3176 - val_root_mean_squared_error: 3.7644 - lr: 2.5000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 28/1000\n",
      "290/290 - 2s - loss: 10.6924 - root_mean_squared_error: 3.2474 - val_loss: 14.3576 - val_root_mean_squared_error: 3.7697 - lr: 2.5000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 29/1000\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "290/290 - 2s - loss: 10.6804 - root_mean_squared_error: 3.2455 - val_loss: 14.3862 - val_root_mean_squared_error: 3.7734 - lr: 2.5000e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 30/1000\n",
      "290/290 - 2s - loss: 10.6215 - root_mean_squared_error: 3.2364 - val_loss: 14.3499 - val_root_mean_squared_error: 3.7686 - lr: 1.2500e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 31/1000\n",
      "290/290 - 2s - loss: 10.6021 - root_mean_squared_error: 3.2333 - val_loss: 14.3129 - val_root_mean_squared_error: 3.7637 - lr: 1.2500e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 32/1000\n",
      "290/290 - 2s - loss: 10.5968 - root_mean_squared_error: 3.2325 - val_loss: 14.4153 - val_root_mean_squared_error: 3.7772 - lr: 1.2500e-04 - 2s/epoch - 7ms/step\n",
      "Epoch 33/1000\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "290/290 - 2s - loss: 10.5844 - root_mean_squared_error: 3.2306 - val_loss: 14.4017 - val_root_mean_squared_error: 3.7754 - lr: 1.2500e-04 - 2s/epoch - 7ms/step\n",
      "INFO:tensorflow:Assets written to: model/model_2\\assets\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Fold 2:  32 epochs, corr =  0.66157\n",
      "\u001b[32m\u001b[1mAverage  corr = 0.66723\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "VERBOSE = 2 # set to 2 for more output, set to 0 for less output\n",
    "EPOCHS = 1000\n",
    "N_SPLITS = 3\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "kf = GroupKFold(n_splits=N_SPLITS)\n",
    "score_list = []\n",
    "for fold, (idx_tr, idx_va) in enumerate(kf.split(X, groups=meta.donor)):\n",
    "    start_time = datetime.datetime.now()\n",
    "    model = None\n",
    "    gc.collect()\n",
    "    X_tr = X[idx_tr]\n",
    "    y_tr = train_target[idx_tr]\n",
    "    X_va = X[idx_va]\n",
    "    y_va = train_target[idx_va]\n",
    "    y_va_raw = train_targets[idx_va]\n",
    "\n",
    "    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, \n",
    "                           patience=4, verbose=VERBOSE)\n",
    "    es = EarlyStopping(monitor=\"val_loss\",\n",
    "                       patience=12, \n",
    "                       verbose=0,\n",
    "                       mode=\"min\", \n",
    "                       restore_best_weights=True)\n",
    "    ckpt = tf.keras.callbacks.ModelCheckpoint(f\"model/model_{fold}_ckpt\", save_best_only=True)\n",
    "    callbacks = [lr, es, tf.keras.callbacks.TerminateOnNaN(), ckpt]\n",
    "\n",
    "    # Construct and compile the model\n",
    "    model = my_model(best_hp, X_tr.shape[1])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_tr, y_tr, \n",
    "                        validation_data=(X_va, y_va), \n",
    "                        epochs=EPOCHS,\n",
    "                        verbose=VERBOSE,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        callbacks=callbacks)\n",
    "    del X_tr, y_tr\n",
    "    if SUBMIT:\n",
    "        model.save(f\"model/model_{fold}\")\n",
    "    history = history.history\n",
    "    callbacks, lr = None, None\n",
    "    \n",
    "    # We validate the model\n",
    "    y_va_pred = model.predict(X_va, batch_size=len(X_va))\n",
    "    corrscore = correlation_score(y_va_raw.todense(), y_va_pred@pca2.components_)\n",
    "\n",
    "    print(f\"Fold {fold}: {es.stopped_epoch:3} epochs, corr =  {corrscore:.5f}\")\n",
    "    del es, X_va#, y_va, y_va_pred\n",
    "    score_list.append(corrscore)\n",
    "\n",
    "# Show overall score\n",
    "print(f\"{Fore.GREEN}{Style.BRIGHT}Average  corr = {np.array(score_list).mean():.5f}{Style.RESET_ALL}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaf96ac",
   "metadata": {
    "papermill": {
     "duration": 0.009292,
     "end_time": "2022-10-02T05:34:39.613783",
     "exception": false,
     "start_time": "2022-10-02T05:34:39.604491",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Cross-validation shows us the average correlation between predictions and ground truth. The histogram additionally shows how the correlations of the cells are distributed. While most correlations are around 0.9, there exist a few predictions with negative correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94fac5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_test_x = scipy.sparse.load_npz(\"C:/Users/Owner/Documents/dev/open-problem/multimodal-single-cell-as-sparse-matrix/test_multi_inputs_values.sparse.npz\")\n",
    "multi_test_x = svd.transform(multi_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8da0f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29696"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=1\n",
    "test_len = multi_test_x.shape[0]\n",
    "d = test_len//n\n",
    "x = []\n",
    "for i in range(n):\n",
    "    x.append(multi_test_x[i*d:i*d+d])\n",
    "del multi_test_x\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68c1a0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with fold 0\n",
      "1748/1748 [==============================] - 3s 1ms/step\n",
      "Predicting with fold 1\n",
      "1748/1748 [==============================] - 2s 1ms/step\n",
      "Predicting with fold 2\n",
      "1748/1748 [==============================] - 2s 1ms/step\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.zeros((test_len, 23418), dtype='float16')\n",
    "for i,xx in enumerate(x):\n",
    "    for fold in range(N_SPLITS):\n",
    "        print(f\"Predicting with fold {fold}\")\n",
    "        model = load_model(f\"model/model_{fold}\")\n",
    "        preds[i*d:i*d+d,:] += (model.predict(xx)@pca2.components_)/N_SPLITS\n",
    "        gc.collect()\n",
    "    print('')\n",
    "    del xx\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a82d3060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T05:34:39.635981Z",
     "iopub.status.busy": "2022-10-02T05:34:39.635567Z",
     "iopub.status.idle": "2022-10-02T05:34:42.405386Z",
     "shell.execute_reply": "2022-10-02T05:34:42.404043Z"
    },
    "papermill": {
     "duration": 2.785216,
     "end_time": "2022-10-02T05:34:42.408536",
     "exception": false,
     "start_time": "2022-10-02T05:34:39.623320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the table of rows and columns required for submission\n",
    "eval_ids = pd.read_parquet(\"C:/Users/Owner/Documents/dev/open-problem/multimodal-single-cell-as-sparse-matrix/evaluation.parquet\")\n",
    "# Convert the string columns to more efficient categorical types\n",
    "#eval_ids.cell_id = eval_ids.cell_id.apply(lambda s: int(s, base=16))\n",
    "eval_ids.cell_id = eval_ids.cell_id.astype(pd.CategoricalDtype())\n",
    "eval_ids.gene_id = eval_ids.gene_id.astype(pd.CategoricalDtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "201285f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T05:34:42.449196Z",
     "iopub.status.busy": "2022-10-02T05:34:42.448790Z",
     "iopub.status.idle": "2022-10-02T05:38:27.712103Z",
     "shell.execute_reply": "2022-10-02T05:38:27.710711Z"
    },
    "papermill": {
     "duration": 225.28903,
     "end_time": "2022-10-02T05:38:27.726803",
     "exception": false,
     "start_time": "2022-10-02T05:34:42.437773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id    cell_id       gene_id        \n",
       "0         c2150f55becb  CD86              NaN\n",
       "1         c2150f55becb  CD274             NaN\n",
       "2         c2150f55becb  CD270             NaN\n",
       "3         c2150f55becb  CD155             NaN\n",
       "4         c2150f55becb  CD112             NaN\n",
       "                                           ..\n",
       "65744175  2c53aa67933d  ENSG00000134419   NaN\n",
       "65744176  2c53aa67933d  ENSG00000186862   NaN\n",
       "65744177  2c53aa67933d  ENSG00000170959   NaN\n",
       "65744178  2c53aa67933d  ENSG00000107874   NaN\n",
       "65744179  2c53aa67933d  ENSG00000166012   NaN\n",
       "Name: target, Length: 65744180, dtype: float32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare an empty series which will be filled with predictions\n",
    "submission = pd.Series(name='target',\n",
    "                       index=pd.MultiIndex.from_frame(eval_ids), \n",
    "                       dtype=np.float32)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7746d761",
   "metadata": {
    "papermill": {
     "duration": 0.014067,
     "end_time": "2022-10-02T05:38:27.753901",
     "exception": false,
     "start_time": "2022-10-02T05:38:27.739834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('preds.npy', preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b8e458a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 20 s\n",
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read the table of rows and columns required for submission\n",
    "eval_ids = pd.read_parquet(\"C:/Users/Owner/Documents/dev/open-problem/multimodal-single-cell-as-sparse-matrix/evaluation.parquet\")\n",
    "# Convert the string columns to more efficient categorical types\n",
    "#eval_ids.cell_id = eval_ids.cell_id.apply(lambda s: int(s, base=16))\n",
    "eval_ids.cell_id = eval_ids.cell_id.astype(pd.CategoricalDtype())\n",
    "eval_ids.gene_id = eval_ids.gene_id.astype(pd.CategoricalDtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ad1c8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id    cell_id       gene_id        \n",
       "0         c2150f55becb  CD86              NaN\n",
       "1         c2150f55becb  CD274             NaN\n",
       "2         c2150f55becb  CD270             NaN\n",
       "3         c2150f55becb  CD155             NaN\n",
       "4         c2150f55becb  CD112             NaN\n",
       "                                           ..\n",
       "65744175  2c53aa67933d  ENSG00000134419   NaN\n",
       "65744176  2c53aa67933d  ENSG00000186862   NaN\n",
       "65744177  2c53aa67933d  ENSG00000170959   NaN\n",
       "65744178  2c53aa67933d  ENSG00000107874   NaN\n",
       "65744179  2c53aa67933d  ENSG00000166012   NaN\n",
       "Name: target, Length: 65744180, dtype: float32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare an empty series which will be filled with predictions\n",
    "submission = pd.Series(name='target',\n",
    "                       index=pd.MultiIndex.from_frame(eval_ids), \n",
    "                       dtype=np.float32)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb972cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 34 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_columns = np.load(\"C:/Users/Owner/Documents/dev/open-problem/multimodal-single-cell-as-sparse-matrix/train_multi_targets_idxcol.npz\",\n",
    "                   allow_pickle=True)[\"columns\"]\n",
    "\n",
    "test_index = np.load(\"C:/Users/Owner/Documents/dev/open-problem/multimodal-single-cell-as-sparse-matrix/test_multi_inputs_idxcol.npz\",\n",
    "                    allow_pickle=True)[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc51ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_dict = dict((k,v) for v,k in enumerate(test_index)) \n",
    "assert len(cell_dict)  == len(test_index)\n",
    "\n",
    "gene_dict = dict((k,v) for v,k in enumerate(y_columns))\n",
    "assert len(gene_dict) == len(y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf451ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ids_cell_num = eval_ids.cell_id.apply(lambda x:cell_dict.get(x, -1))\n",
    "eval_ids_gene_num = eval_ids.gene_id.apply(lambda x:gene_dict.get(x, -1))\n",
    "\n",
    "valid_multi_rows = (eval_ids_gene_num !=-1) & (eval_ids_cell_num!=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41d97256",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.iloc[valid_multi_rows] = preds[eval_ids_cell_num[valid_multi_rows].to_numpy(),\n",
    "eval_ids_gene_num[valid_multi_rows].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57cd2506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del eval_ids_cell_num, eval_ids_gene_num, valid_multi_rows, eval_ids, test_index, y_columns\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1f4c81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id    cell_id       gene_id        \n",
       "0         c2150f55becb  CD86                    NaN\n",
       "1         c2150f55becb  CD274                   NaN\n",
       "2         c2150f55becb  CD270                   NaN\n",
       "3         c2150f55becb  CD155                   NaN\n",
       "4         c2150f55becb  CD112                   NaN\n",
       "                                             ...   \n",
       "65744175  2c53aa67933d  ENSG00000134419    5.695312\n",
       "65744176  2c53aa67933d  ENSG00000186862    0.036163\n",
       "65744177  2c53aa67933d  ENSG00000170959    0.034607\n",
       "65744178  2c53aa67933d  ENSG00000107874    1.027344\n",
       "65744179  2c53aa67933d  ENSG00000166012    5.078125\n",
       "Name: target, Length: 65744180, dtype: float32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f96119b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.reset_index(drop=True, inplace=True)\n",
    "submission.index.name = 'row_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e3fd3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cite_submission = pd.read_csv(\"C:/Users/Owner/Documents/dev/open-problem/citeseq/submission_svd256_wdo.csv\")\n",
    "cite_submission = cite_submission.set_index(\"row_id\")\n",
    "cite_submission = cite_submission[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bccbf7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[submission.isnull()] = cite_submission[submission.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7c00298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca0f608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(submission_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1199.922254,
   "end_time": "2022-10-02T05:38:31.131213",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-02T05:18:31.208959",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "0dc5be61c8cf786c9afde4d6369564156d9ad36efd591152a3b3e204603eb87a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

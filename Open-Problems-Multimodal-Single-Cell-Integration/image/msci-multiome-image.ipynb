{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad1dc45f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.008747,
     "end_time": "2022-10-02T05:18:40.947719",
     "exception": false,
     "start_time": "2022-10-02T05:18:40.938972",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CITEseq Keras Quickstart\n",
    "\n",
    "This notebook shows how to tune and cross-validate a Keras model for the CITEseq part of the *Multimodal Single-Cell Integration* competition.\n",
    "\n",
    "It does not show the EDA - see the separate notebook [MSCI EDA which makes sense ⭐️⭐️⭐️⭐️⭐️](https://www.kaggle.com/ambrosm/msci-eda-which-makes-sense).\n",
    "\n",
    "The CITEseq predictions of the Keras model are then concatenated with the Multiome predictions of @jsmithperera's [Multiome Quickstart w/ Sparse M + tSVD = 32](https://www.kaggle.com/code/jsmithperera/multiome-quickstart-w-sparse-m-tsvd-32) to a complete submission file.\n",
    "\n",
    "## Summary\n",
    "\n",
    "The CITEseq part of the competition has sizeable datasets, when compared to the standard 16 GByte RAM of Kaggle notebooks:\n",
    "- The training input has shape 70988/*22050 (10.6 GByte).\n",
    "- The training labels have shape 70988/*140.\n",
    "- The test input has shape 48663/*22050 (4.3 GByte).\n",
    "\n",
    "Our solution strategy has five elements:\n",
    "1. **Dimensionality reduction:** To reduce the size of the 10.6 GByte input data, we project the 22050 features to a space with only 64 dimensions by applying a truncated SVD. To these 64 dimensions, we add 144 features whose names shows their importance.\n",
    "2. **The model:** The model is a sequential dense network with four hidden layers.\n",
    "3. **The loss function:** The competition is scored by the average Pearson correlation coefficient between the predictions and the ground truth. As this scoring function is differentiable, we can directly use it as loss function for a neural network. This gives neural networks an advantage in comparison to algorithms which use mean squared error as a surrogate loss. \n",
    "3. **Hyperparameter tuning with KerasTuner:** We tune the hyperparameters with [KerasTuner](https://keras.io/keras_tuner/). \n",
    "4. **Cross-validation:** Submitting unvalidated models and relying only on the public leaderboard is bad practice. The model in this notebook is fully cross-validated with a 3-fold GroupKFold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73080787",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-10-02T05:18:40.966045Z",
     "iopub.status.busy": "2022-10-02T05:18:40.964979Z",
     "iopub.status.idle": "2022-10-02T05:18:49.652688Z",
     "shell.execute_reply": "2022-10-02T05:18:49.651353Z"
    },
    "papermill": {
     "duration": 8.700798,
     "end_time": "2022-10-02T05:18:49.655978",
     "exception": false,
     "start_time": "2022-10-02T05:18:40.955180",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os, gc, pickle, datetime, scipy.sparse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, scale, MinMaxScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "# import keras_tuner\n",
    "# from tensorflow.keras import mixed_precision\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_global_policy(policy)\n",
    "\n",
    "DATA_DIR = \"C:/Users/Owner/Documents/dev/open-problem/open-problems-multimodal/\"\n",
    "FP_CELL_METADATA = os.path.join(DATA_DIR,\"metadata.csv\")\n",
    "\n",
    "FP_CITE_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_cite_inputs.h5\")\n",
    "FP_CITE_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_cite_targets.h5\")\n",
    "FP_CITE_TEST_INPUTS = os.path.join(DATA_DIR,\"test_cite_inputs.h5\")\n",
    "\n",
    "FP_MULTIOME_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_multi_inputs.h5\")\n",
    "FP_MULTIOME_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_multi_targets.h5\")\n",
    "FP_MULTIOME_TEST_INPUTS = os.path.join(DATA_DIR,\"test_multi_inputs.h5\")\n",
    "\n",
    "FP_SUBMISSION = os.path.join(DATA_DIR,\"sample_submission.csv\")\n",
    "FP_EVALUATION_IDS = os.path.join(DATA_DIR,\"evaluation_ids.csv\")\n",
    "\n",
    "TUNE = False\n",
    "SUBMIT = True\n",
    "TRAIN_BASEPATH = \"C:/Users/Owner/Documents/dev/open-problem/output/imagedata/multi-minmax/train/\"\n",
    "TEST_BASEPATH = \"C:/Users/Owner/Documents/dev/open-problem/output/imagedata/multi-minmax/test/\"\n",
    "USE_SAVED_PCA = True\n",
    "\n",
    "submission_name = \"submission_multiome_image_B0_480.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25ee6394",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "submission_name = \"submission_multiome_image_240.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07302299",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 5790987839807812232\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 22388146176\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 6678153743473512010\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:2b:00.0, compute capability: 8.9\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1c1a5b2",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Documents\\dev\\open-problem\\multiome-image\n"
     ]
    }
   ],
   "source": [
    "%cd C:/Users/Owner/Documents/dev/open-problem/multiome-image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d15ec7",
   "metadata": {
    "papermill": {
     "duration": 0.007252,
     "end_time": "2022-10-02T05:18:49.670748",
     "exception": false,
     "start_time": "2022-10-02T05:18:49.663496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A little trick to save time with pip: If the module is already installed (after a restart of the notebook, for instance), pip wastes 10 seconds by checking whether a newer version exists. We can skip this check by testing for the presence of the module in a simple if statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "539e35ad",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-10-02T05:18:49.688119Z",
     "iopub.status.busy": "2022-10-02T05:18:49.686761Z",
     "iopub.status.idle": "2022-10-02T05:19:06.804207Z",
     "shell.execute_reply": "2022-10-02T05:19:06.803199Z"
    },
    "papermill": {
     "duration": 17.129669,
     "end_time": "2022-10-02T05:19:06.807709",
     "exception": false,
     "start_time": "2022-10-02T05:18:49.678040",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# If you see a warning \"Failed to establish a new connection\" running this cell,\n",
    "# go to \"Settings\" on the right hand side, \n",
    "# and turn on internet. Note, you need to be phone verified.\n",
    "# We need this library to read HDF files.\n",
    "# if not os.path.exists('/opt/conda/lib/python3.7/site-packages/tables'):\n",
    "#     !pip install --quiet tables\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35cfbd0",
   "metadata": {
    "papermill": {
     "duration": 0.007106,
     "end_time": "2022-10-02T05:19:06.823152",
     "exception": false,
     "start_time": "2022-10-02T05:19:06.816046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The scoring function\n",
    "\n",
    "This competition has a special metric: For every row, it computes the Pearson correlation between y_true and y_pred, and then all these correlation coefficients are averaged. We implement two variants of the metric: The first one is for numpy arrays, the second one for tensors - thanks to @lucasmorin for the [original tensor implementation](https://www.kaggle.com/competitions/open-problems-multimodal/discussion/347595)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b8058e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T05:19:06.840828Z",
     "iopub.status.busy": "2022-10-02T05:19:06.840348Z",
     "iopub.status.idle": "2022-10-02T05:19:06.851764Z",
     "shell.execute_reply": "2022-10-02T05:19:06.850574Z"
    },
    "papermill": {
     "duration": 0.023744,
     "end_time": "2022-10-02T05:19:06.854538",
     "exception": false,
     "start_time": "2022-10-02T05:19:06.830794",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def correlation_score(y_true, y_pred):\n",
    "    \"\"\"Scores the predictions according to the competition rules. \n",
    "    \n",
    "    It is assumed that the predictions are not constant.\n",
    "    \n",
    "    Returns the average of each sample's Pearson correlation coefficient\"\"\"\n",
    "    if type(y_true) == pd.DataFrame: y_true = y_true.values\n",
    "    if type(y_pred) == pd.DataFrame: y_pred = y_pred.values\n",
    "    corrsum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        corrsum += np.corrcoef(y_true[i], y_pred[i])[1, 0]\n",
    "    return corrsum / len(y_true)\n",
    "\n",
    "def negative_correlation_loss(y_true, y_pred):\n",
    "    \"\"\"Negative correlation loss function for Keras\n",
    "    \n",
    "    Precondition:\n",
    "    y_true.mean(axis=1) == 0\n",
    "    y_true.std(axis=1) == 1\n",
    "    \n",
    "    Returns:\n",
    "    -1 = perfect positive correlation\n",
    "    1 = totally negative correlation\n",
    "    \"\"\"\n",
    "    my = K.mean(tf.convert_to_tensor(y_pred), axis=1)\n",
    "    my = tf.tile(tf.expand_dims(my, axis=1), (1, y_true.shape[1]))\n",
    "    ym = y_pred - my\n",
    "    r_num = K.sum(tf.multiply(y_true, ym), axis=1)\n",
    "    r_den = tf.sqrt(K.sum(K.square(ym), axis=1) * float(y_true.shape[-1]))\n",
    "    r = tf.reduce_mean(r_num / r_den)\n",
    "    return - r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688a2749",
   "metadata": {
    "papermill": {
     "duration": 0.007031,
     "end_time": "2022-10-02T05:19:06.869083",
     "exception": false,
     "start_time": "2022-10-02T05:19:06.862052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data loading and preprocessing\n",
    "\n",
    "The metadata is used only for the `GroupKFold`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73c29484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T05:19:06.885600Z",
     "iopub.status.busy": "2022-10-02T05:19:06.885168Z",
     "iopub.status.idle": "2022-10-02T05:19:07.439994Z",
     "shell.execute_reply": "2022-10-02T05:19:07.438675Z"
    },
    "papermill": {
     "duration": 0.566235,
     "end_time": "2022-10-02T05:19:07.442631",
     "exception": false,
     "start_time": "2022-10-02T05:19:06.876396",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161877, 4)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df = pd.read_csv(FP_CELL_METADATA, index_col='cell_id')\n",
    "metadata_df = metadata_df[metadata_df.technology==\"multiome\"]\n",
    "metadata_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c2c03bf",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>donor</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>technology</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>458c2ae2c9b1</th>\n",
       "      <td>2</td>\n",
       "      <td>27678</td>\n",
       "      <td>hidden</td>\n",
       "      <td>multiome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01a0659b0710</th>\n",
       "      <td>2</td>\n",
       "      <td>27678</td>\n",
       "      <td>hidden</td>\n",
       "      <td>multiome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>028a8bc3f2ba</th>\n",
       "      <td>2</td>\n",
       "      <td>27678</td>\n",
       "      <td>hidden</td>\n",
       "      <td>multiome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7ec0ca8bb863</th>\n",
       "      <td>2</td>\n",
       "      <td>27678</td>\n",
       "      <td>hidden</td>\n",
       "      <td>multiome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caa0b0022cdc</th>\n",
       "      <td>2</td>\n",
       "      <td>27678</td>\n",
       "      <td>hidden</td>\n",
       "      <td>multiome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              day  donor cell_type technology\n",
       "cell_id                                      \n",
       "458c2ae2c9b1    2  27678    hidden   multiome\n",
       "01a0659b0710    2  27678    hidden   multiome\n",
       "028a8bc3f2ba    2  27678    hidden   multiome\n",
       "7ec0ca8bb863    2  27678    hidden   multiome\n",
       "caa0b0022cdc    2  27678    hidden   multiome"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ba85b2c0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "cell_index = np.load(\"C:/Users/Owner/Documents/dev/open-problem/multimodal-single-cell-as-sparse-matrix/train_multi_inputs_idxcol.npz\", allow_pickle=True)[\"index\"]\n",
    "meta = metadata_df.reindex(cell_index)\n",
    "cell_index_test = np.load(\"C:/Users/Owner/Documents/dev/open-problem/multimodal-single-cell-as-sparse-matrix/test_multi_inputs_idxcol.npz\", allow_pickle=True)[\"index\"]\n",
    "meta_test = metadata_df.reindex(cell_index_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72714930",
   "metadata": {
    "papermill": {
     "duration": 0.007295,
     "end_time": "2022-10-02T05:19:07.457595",
     "exception": false,
     "start_time": "2022-10-02T05:19:07.450300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We now define two sets of features:\n",
    "- `constant_cols` is the set of all features which are constant in the train or test datset. These columns will be discarded immediately after loading.\n",
    "- `important_cols` is the set of all features whose name matches the name of a target protein. If a gene is named 'ENSG00000114013_CD86', it should be related to a protein named 'CD86'. These features will be used for the model unchanged, that is, they don't undergo dimensionality reduction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7624570",
   "metadata": {
    "papermill": {
     "duration": 0.007302,
     "end_time": "2022-10-02T05:19:07.562801",
     "exception": false,
     "start_time": "2022-10-02T05:19:07.555499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We read train and test datasets, keep the important columns and convert the rest to sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5845aabe",
   "metadata": {
    "papermill": {
     "duration": 0.007601,
     "end_time": "2022-10-02T05:22:07.667933",
     "exception": false,
     "start_time": "2022-10-02T05:22:07.660332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We apply the truncated SVD to train and test together. The truncated SVD is memory-efficient. We concatenate the SVD output (64 components) with the 144 important features and get the arrays `X` and `Xt`, which will be the input to the Keras model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9fd08d33",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def save(name, model):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9575a96d",
   "metadata": {
    "papermill": {
     "duration": 0.007643,
     "end_time": "2022-10-02T05:26:18.534066",
     "exception": false,
     "start_time": "2022-10-02T05:26:18.526423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, we read the target array `Y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0378f7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T05:26:18.552052Z",
     "iopub.status.busy": "2022-10-02T05:26:18.551600Z",
     "iopub.status.idle": "2022-10-02T05:26:19.281910Z",
     "shell.execute_reply": "2022-10-02T05:26:19.280763Z"
    },
    "papermill": {
     "duration": 0.742869,
     "end_time": "2022-10-02T05:26:19.284853",
     "exception": false,
     "start_time": "2022-10-02T05:26:18.541984",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Read Y\n",
    "Y = scipy.sparse.load_npz(\"C:/Users/Owner/Documents/dev/open-problem/multimodal-single-cell-as-sparse-matrix/train_multi_targets_values.sparse.npz\")\n",
    "\n",
    "if USE_SAVED_PCA:\n",
    "    pca2 = pickle.load(open('pca2.pkl', 'rb'))\n",
    "    train_target = pca2.transform(Y)\n",
    "else:\n",
    "    pca2 = TruncatedSVD(n_components=256, random_state=42)\n",
    "    train_target = pca2.fit_transform(Y)\n",
    "    print(pca2.explained_variance_ratio_.sum())\n",
    "    save('pca2.pkl', pca2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15b9c6dd",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 480, 480, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Function  (None, 15, 15, 1280)     5919312   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 256)               327936    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,247,248\n",
      "Trainable params: 6,186,640\n",
      "Non-trainable params: 60,608\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LR_START = 0.01\n",
    "BATCH_SIZE = 64\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "SHUFFLE_SIZE = 10000\n",
    "WIDTH = 480\n",
    "HEIGHT = 480\n",
    "EPOCHS = 50\n",
    "OUTPUT_LEN = train_target.shape[1]\n",
    "\n",
    "def preprocess_image(image):\n",
    "#     image = tfio.experimental.image.decode_tiff(path)[...,:3]\n",
    "    image = tf.io.decode_png(image, channels=1, dtype=tf.dtypes.uint16)\n",
    "    image = tf.image.resize(image, size=(WIDTH,HEIGHT), method=\"nearest\")\n",
    "    image = tf.broadcast_to(image, (image.shape[0], image.shape[1], 3))\n",
    "    image = tf.reshape(image, shape=[WIDTH,HEIGHT,3])\n",
    "\n",
    "    # image = tf.keras.applications.efficientnet.preprocess_input(image)\n",
    "    image = tf.keras.applications.efficientnet_v2.preprocess_input(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image)\n",
    "\n",
    "def load_and_preprocess_from_path_label(path, label):\n",
    "    return load_and_preprocess_image(path), label\n",
    "\n",
    "def load_and_preprocess_from_path(path):\n",
    "    return load_and_preprocess_image(path)\n",
    "\n",
    "def my_model():\n",
    "    \"\"\"Sequential neural network\n",
    "    \n",
    "    Returns a compiled instance of tensorflow.keras.models.Model.\n",
    "    \"\"\"\n",
    "    basemodel = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(input_shape=(WIDTH, HEIGHT, 3), weights='imagenet', include_top=False, include_preprocessing=False)\n",
    "    # basemodel = tf.keras.applications.efficientnet_v2.EfficientNetV2S(input_shape=(WIDTH, HEIGHT, 3), weights='imagenet', include_top=False, include_preprocessing=False)\n",
    "    # basemodel = tf.keras.applications.efficientnet.EfficientNetB0(input_shape=(WIDTH, HEIGHT, 3), weights='imagenet', include_top=False)\n",
    "\n",
    "    image_input = tf.keras.layers.Input(shape=(WIDTH,HEIGHT,3))\n",
    "    out = basemodel(image_input)\n",
    "    out = tf.keras.layers.GlobalAveragePooling2D()(out)\n",
    "    out = tf.keras.layers.Dropout(0.5)(out)\n",
    "    out = tf.keras.layers.Dense(OUTPUT_LEN, activation=None, kernel_regularizer=tf.keras.regularizers.l2(1e-10))(out)\n",
    "\n",
    "    model = tf.keras.Model(image_input, out)\n",
    "\n",
    "    # model.compile(optimizer=tf.keras.mixed_precision.LossScaleOptimizer(tf.keras.optimizers.Adam()), \n",
    "    #             loss=root_mean_squared_error,\n",
    "    #             metrics=[root_mean_squared_error])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()])  \n",
    "    return model\n",
    "\n",
    "my_model().summary()\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "# Cross-validation\n",
    "VERBOSE = 2 # set to 2 for more output, set to 0 for less output\n",
    "N_SPLITS = 3\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "kf = GroupKFold(n_splits=N_SPLITS)\n",
    "\n",
    "score_list = []\n",
    "train_paths = TRAIN_BASEPATH + cell_index + \".png\"\n",
    "histories = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5397b09",
   "metadata": {
    "papermill": {
     "duration": 0.007767,
     "end_time": "2022-10-02T05:26:19.300772",
     "exception": false,
     "start_time": "2022-10-02T05:26:19.293005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The model\n",
    "\n",
    "Our model is a sequential network consisting of a few dense layers. The hyperparameters will be tuned with KerasTuner.\n",
    "\n",
    "We use the `negative_correlation_loss` defined above as loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8078ea07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T05:26:19.318297Z",
     "iopub.status.busy": "2022-10-02T05:26:19.317861Z",
     "iopub.status.idle": "2022-10-02T05:26:20.787213Z",
     "shell.execute_reply": "2022-10-02T05:26:20.785795Z"
    },
    "papermill": {
     "duration": 1.481658,
     "end_time": "2022-10-02T05:26:20.790253",
     "exception": false,
     "start_time": "2022-10-02T05:26:19.308595",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1079/1079 [==============================] - ETA: 0s - loss: 51.3475 - root_mean_squared_error: 7.1657"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079/1079 [==============================] - 519s 467ms/step - loss: 51.3475 - root_mean_squared_error: 7.1657 - val_loss: 40.4572 - val_root_mean_squared_error: 6.3606 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1079/1079 [==============================] - ETA: 0s - loss: 22.2223 - root_mean_squared_error: 4.7141"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079/1079 [==============================] - 507s 470ms/step - loss: 22.2223 - root_mean_squared_error: 4.7141 - val_loss: 29.6522 - val_root_mean_squared_error: 5.4454 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1079/1079 [==============================] - ETA: 0s - loss: 20.2432 - root_mean_squared_error: 4.4992"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079/1079 [==============================] - 502s 465ms/step - loss: 20.2432 - root_mean_squared_error: 4.4992 - val_loss: 27.1464 - val_root_mean_squared_error: 5.2102 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1079/1079 [==============================] - ETA: 0s - loss: 19.1415 - root_mean_squared_error: 4.3751"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079/1079 [==============================] - 496s 460ms/step - loss: 19.1415 - root_mean_squared_error: 4.3751 - val_loss: 24.0981 - val_root_mean_squared_error: 4.9090 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1079/1079 [==============================] - ETA: 0s - loss: 18.2977 - root_mean_squared_error: 4.2776"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079/1079 [==============================] - 478s 442ms/step - loss: 18.2977 - root_mean_squared_error: 4.2776 - val_loss: 21.7210 - val_root_mean_squared_error: 4.6606 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1079/1079 [==============================] - ETA: 0s - loss: 17.6122 - root_mean_squared_error: 4.1967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079/1079 [==============================] - 476s 441ms/step - loss: 17.6122 - root_mean_squared_error: 4.1967 - val_loss: 21.0145 - val_root_mean_squared_error: 4.5842 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1079/1079 [==============================] - 446s 413ms/step - loss: 16.9576 - root_mean_squared_error: 4.1180 - val_loss: 22.0111 - val_root_mean_squared_error: 4.6916 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1079/1079 [==============================] - 446s 413ms/step - loss: 16.4882 - root_mean_squared_error: 4.0606 - val_loss: 25.7534 - val_root_mean_squared_error: 5.0748 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1079/1079 [==============================] - ETA: 0s - loss: 16.0229 - root_mean_squared_error: 4.0029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079/1079 [==============================] - 475s 440ms/step - loss: 16.0229 - root_mean_squared_error: 4.0029 - val_loss: 20.7954 - val_root_mean_squared_error: 4.5602 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1079/1079 [==============================] - ETA: 0s - loss: 15.5762 - root_mean_squared_error: 3.9467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079/1079 [==============================] - 475s 440ms/step - loss: 15.5762 - root_mean_squared_error: 3.9467 - val_loss: 20.6451 - val_root_mean_squared_error: 4.5437 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1079/1079 [==============================] - 446s 413ms/step - loss: 15.2223 - root_mean_squared_error: 3.9016 - val_loss: 21.0836 - val_root_mean_squared_error: 4.5917 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1079/1079 [==============================] - ETA: 0s - loss: 14.8725 - root_mean_squared_error: 3.8565"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079/1079 [==============================] - 475s 441ms/step - loss: 14.8725 - root_mean_squared_error: 3.8565 - val_loss: 19.6701 - val_root_mean_squared_error: 4.4351 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1079/1079 [==============================] - 446s 413ms/step - loss: 14.5487 - root_mean_squared_error: 3.8143 - val_loss: 23.1173 - val_root_mean_squared_error: 4.8081 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1079/1079 [==============================] - 450s 417ms/step - loss: 14.2580 - root_mean_squared_error: 3.7760 - val_loss: 22.6721 - val_root_mean_squared_error: 4.7615 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1079/1079 [==============================] - ETA: 0s - loss: 13.9853 - root_mean_squared_error: 3.7397\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "1079/1079 [==============================] - 448s 415ms/step - loss: 13.9853 - root_mean_squared_error: 3.7397 - val_loss: 19.9949 - val_root_mean_squared_error: 4.4716 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1079/1079 [==============================] - ETA: 0s - loss: 13.2493 - root_mean_squared_error: 3.6400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_0_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079/1079 [==============================] - 474s 439ms/step - loss: 13.2493 - root_mean_squared_error: 3.6400 - val_loss: 19.4566 - val_root_mean_squared_error: 4.4110 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "1079/1079 [==============================] - 462s 428ms/step - loss: 12.9415 - root_mean_squared_error: 3.5974 - val_loss: 20.1076 - val_root_mean_squared_error: 4.4842 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "1079/1079 [==============================] - 468s 433ms/step - loss: 12.7185 - root_mean_squared_error: 3.5663 - val_loss: 20.2969 - val_root_mean_squared_error: 4.5052 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "1079/1079 [==============================] - ETA: 0s - loss: 12.5555 - root_mean_squared_error: 3.5434\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1079/1079 [==============================] - 454s 421ms/step - loss: 12.5555 - root_mean_squared_error: 3.5434 - val_loss: 20.7623 - val_root_mean_squared_error: 4.5566 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "1079/1079 [==============================] - 446s 414ms/step - loss: 12.2429 - root_mean_squared_error: 3.4990 - val_loss: 19.9592 - val_root_mean_squared_error: 4.4676 - lr: 2.5000e-04\n",
      "Epoch 21/50\n",
      "1079/1079 [==============================] - 446s 413ms/step - loss: 12.0734 - root_mean_squared_error: 3.4747 - val_loss: 20.1163 - val_root_mean_squared_error: 4.4851 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model_0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model_0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 49s 83ms/step\n",
      "Fold 0:  20 epochs, corr =  0.65410\n",
      "Epoch 1/50\n",
      "1102/1102 [==============================] - ETA: 0s - loss: 51.4570 - root_mean_squared_error: 7.1734"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1102/1102 [==============================] - 494s 437ms/step - loss: 51.4570 - root_mean_squared_error: 7.1734 - val_loss: 28.2351 - val_root_mean_squared_error: 5.3137 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1102/1102 [==============================] - ETA: 0s - loss: 22.6294 - root_mean_squared_error: 4.7570"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1102/1102 [==============================] - 480s 435ms/step - loss: 22.6294 - root_mean_squared_error: 4.7570 - val_loss: 27.1496 - val_root_mean_squared_error: 5.2105 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1102/1102 [==============================] - ETA: 0s - loss: 20.7341 - root_mean_squared_error: 4.5535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1102/1102 [==============================] - 481s 436ms/step - loss: 20.7341 - root_mean_squared_error: 4.5535 - val_loss: 27.0384 - val_root_mean_squared_error: 5.1999 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1102/1102 [==============================] - ETA: 0s - loss: 19.6776 - root_mean_squared_error: 4.4359"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1102/1102 [==============================] - 480s 435ms/step - loss: 19.6776 - root_mean_squared_error: 4.4359 - val_loss: 26.5140 - val_root_mean_squared_error: 5.1492 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1102/1102 [==============================] - ETA: 0s - loss: 18.8713 - root_mean_squared_error: 4.3441"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1102/1102 [==============================] - 480s 435ms/step - loss: 18.8713 - root_mean_squared_error: 4.3441 - val_loss: 23.1860 - val_root_mean_squared_error: 4.8152 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1102/1102 [==============================] - ETA: 0s - loss: 18.1764 - root_mean_squared_error: 4.2634"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1102/1102 [==============================] - 481s 436ms/step - loss: 18.1764 - root_mean_squared_error: 4.2634 - val_loss: 22.5781 - val_root_mean_squared_error: 4.7516 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1102/1102 [==============================] - ETA: 0s - loss: 17.5523 - root_mean_squared_error: 4.1895"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1102/1102 [==============================] - 480s 436ms/step - loss: 17.5523 - root_mean_squared_error: 4.1895 - val_loss: 22.1547 - val_root_mean_squared_error: 4.7069 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1102/1102 [==============================] - ETA: 0s - loss: 17.0550 - root_mean_squared_error: 4.1298"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1102/1102 [==============================] - 481s 436ms/step - loss: 17.0550 - root_mean_squared_error: 4.1298 - val_loss: 20.7913 - val_root_mean_squared_error: 4.5597 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1102/1102 [==============================] - ETA: 0s - loss: 16.6434 - root_mean_squared_error: 4.0796"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_1_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1102/1102 [==============================] - 480s 435ms/step - loss: 16.6434 - root_mean_squared_error: 4.0796 - val_loss: 19.7114 - val_root_mean_squared_error: 4.4397 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1102/1102 [==============================] - 451s 409ms/step - loss: 16.2391 - root_mean_squared_error: 4.0298 - val_loss: 20.9863 - val_root_mean_squared_error: 4.5811 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1102/1102 [==============================] - 451s 409ms/step - loss: 15.8693 - root_mean_squared_error: 3.9836 - val_loss: 27.3272 - val_root_mean_squared_error: 5.2275 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1102/1102 [==============================] - ETA: 0s - loss: 15.4984 - root_mean_squared_error: 3.9368\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "1102/1102 [==============================] - 451s 409ms/step - loss: 15.4984 - root_mean_squared_error: 3.9368 - val_loss: 26.0070 - val_root_mean_squared_error: 5.0997 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1102/1102 [==============================] - 451s 409ms/step - loss: 14.7767 - root_mean_squared_error: 3.8441 - val_loss: 20.7886 - val_root_mean_squared_error: 4.5594 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "1102/1102 [==============================] - 451s 409ms/step - loss: 14.3696 - root_mean_squared_error: 3.7907 - val_loss: 20.5627 - val_root_mean_squared_error: 4.5346 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554/554 [==============================] - 47s 82ms/step\n",
      "Fold 1:  13 epochs, corr =  0.65784\n",
      "Epoch 1/50\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 51.8795 - root_mean_squared_error: 7.2027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128/1128 [==============================] - 500s 432ms/step - loss: 51.8795 - root_mean_squared_error: 7.2027 - val_loss: 28.7786 - val_root_mean_squared_error: 5.3646 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 22.7819 - root_mean_squared_error: 4.7730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128/1128 [==============================] - 487s 431ms/step - loss: 22.7819 - root_mean_squared_error: 4.7730 - val_loss: 28.4642 - val_root_mean_squared_error: 5.3352 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 21.2379 - root_mean_squared_error: 4.6085"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128/1128 [==============================] - 487s 431ms/step - loss: 21.2379 - root_mean_squared_error: 4.6085 - val_loss: 27.6332 - val_root_mean_squared_error: 5.2567 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1128/1128 [==============================] - 457s 405ms/step - loss: 20.2516 - root_mean_squared_error: 4.5002 - val_loss: 28.0398 - val_root_mean_squared_error: 5.2953 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 19.4592 - root_mean_squared_error: 4.4113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128/1128 [==============================] - 486s 431ms/step - loss: 19.4592 - root_mean_squared_error: 4.4113 - val_loss: 22.8094 - val_root_mean_squared_error: 4.7759 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1128/1128 [==============================] - 458s 406ms/step - loss: 18.8417 - root_mean_squared_error: 4.3407 - val_loss: 24.7758 - val_root_mean_squared_error: 4.9775 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1128/1128 [==============================] - 458s 406ms/step - loss: 18.1561 - root_mean_squared_error: 4.2610 - val_loss: 23.0002 - val_root_mean_squared_error: 4.7958 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 17.6779 - root_mean_squared_error: 4.2045\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "1128/1128 [==============================] - 458s 406ms/step - loss: 17.6779 - root_mean_squared_error: 4.2045 - val_loss: 30.3560 - val_root_mean_squared_error: 5.5096 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 16.8597 - root_mean_squared_error: 4.1061"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128/1128 [==============================] - 487s 432ms/step - loss: 16.8597 - root_mean_squared_error: 4.1061 - val_loss: 19.5409 - val_root_mean_squared_error: 4.4205 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "1128/1128 [==============================] - 458s 405ms/step - loss: 16.4029 - root_mean_squared_error: 4.0500 - val_loss: 21.2763 - val_root_mean_squared_error: 4.6126 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "1128/1128 [==============================] - 457s 406ms/step - loss: 16.0427 - root_mean_squared_error: 4.0053 - val_loss: 21.3918 - val_root_mean_squared_error: 4.6251 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 15.7346 - root_mean_squared_error: 3.9667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\model_2_ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128/1128 [==============================] - 487s 431ms/step - loss: 15.7346 - root_mean_squared_error: 3.9667 - val_loss: 19.2586 - val_root_mean_squared_error: 4.3885 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "1128/1128 [==============================] - 458s 405ms/step - loss: 15.4616 - root_mean_squared_error: 3.9321 - val_loss: 20.6268 - val_root_mean_squared_error: 4.5417 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "1128/1128 [==============================] - 457s 406ms/step - loss: 15.1977 - root_mean_squared_error: 3.8984 - val_loss: 19.9452 - val_root_mean_squared_error: 4.4660 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 14.9340 - root_mean_squared_error: 3.8645\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1128/1128 [==============================] - 457s 405ms/step - loss: 14.9340 - root_mean_squared_error: 3.8645 - val_loss: 20.0829 - val_root_mean_squared_error: 4.4814 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "1128/1128 [==============================] - 457s 405ms/step - loss: 14.5367 - root_mean_squared_error: 3.8127 - val_loss: 21.0544 - val_root_mean_squared_error: 4.5885 - lr: 2.5000e-04\n",
      "Epoch 17/50\n",
      "1128/1128 [==============================] - 477s 423ms/step - loss: 14.3110 - root_mean_squared_error: 3.7830 - val_loss: 19.7132 - val_root_mean_squared_error: 4.4400 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527/527 [==============================] - 47s 88ms/step\n",
      "Fold 2:  16 epochs, corr =  0.65615\n",
      "\u001b[32m\u001b[1mAverage  corr = 0.65603\u001b[0m\n",
      "{'loss': [51.34752655029297, 22.2222843170166, 20.243244171142578, 19.14145851135254, 18.297685623168945, 17.61215591430664, 16.957605361938477, 16.488203048706055, 16.022851943969727, 15.576175689697266, 15.222289085388184, 14.872523307800293, 14.548664093017578, 14.258044242858887, 13.985260009765625, 13.249289512634277, 12.941478729248047, 12.718510627746582, 12.555530548095703, 12.242939949035645, 12.073394775390625], 'root_mean_squared_error': [7.165718078613281, 4.714051723480225, 4.499249458312988, 4.375095367431641, 4.277579307556152, 4.196683883666992, 4.117961406707764, 4.0605669021606445, 4.00285530090332, 3.946666717529297, 3.9015750885009766, 3.8564910888671875, 3.8142709732055664, 3.77598237991333, 3.739687204360962, 3.6399574279785156, 3.597426652908325, 3.5663020610809326, 3.5433781147003174, 3.4989912509918213, 3.4746789932250977], 'val_loss': [40.45721435546875, 29.65215492248535, 27.146440505981445, 24.098134994506836, 21.72104835510254, 21.0145320892334, 22.01106071472168, 25.753379821777344, 20.795352935791016, 20.645132064819336, 21.083576202392578, 19.670148849487305, 23.11734962463379, 22.67206382751465, 19.994861602783203, 19.456613540649414, 20.107608795166016, 20.296863555908203, 20.762252807617188, 19.959245681762695, 20.116300582885742], 'val_root_mean_squared_error': [6.360598564147949, 5.445379257202148, 5.210224628448486, 4.908985137939453, 4.660584449768066, 4.584160804748535, 4.69159460067749, 5.0747785568237305, 4.560192108154297, 4.543691635131836, 4.5916852951049805, 4.435103893280029, 4.808050155639648, 4.761518955230713, 4.471561431884766, 4.4109649658203125, 4.4841508865356445, 4.505204200744629, 4.556561470031738, 4.4675774574279785, 4.485119819641113], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025]}\n",
      "{'loss': [51.457008361816406, 22.62942123413086, 20.734052658081055, 19.677627563476562, 18.871288299560547, 18.176401138305664, 17.552303314208984, 17.055009841918945, 16.64344024658203, 16.239112854003906, 15.869322776794434, 15.498404502868652, 14.776725769042969, 14.369574546813965], 'root_mean_squared_error': [7.173354148864746, 4.7570390701293945, 4.553465843200684, 4.435946941375732, 4.344109535217285, 4.263378620147705, 4.189546585083008, 4.1297712326049805, 4.079637050628662, 4.029778003692627, 3.9836318492889404, 3.9368011951446533, 3.844050645828247, 3.790722131729126], 'val_loss': [28.23514747619629, 27.14959716796875, 27.0384464263916, 26.514028549194336, 23.185993194580078, 22.578126907348633, 22.15472984313965, 20.791275024414062, 19.711366653442383, 20.98626136779785, 27.32720947265625, 26.007007598876953, 20.788558959960938, 20.562654495239258], 'val_root_mean_squared_error': [5.313675403594971, 5.210526943206787, 5.199850082397461, 5.149177551269531, 4.815183639526367, 4.751644611358643, 4.706881046295166, 4.559744834899902, 4.439748287200928, 4.581076622009277, 5.227543354034424, 5.099706649780273, 4.559446811676025, 4.534606456756592], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005]}\n",
      "{'loss': [51.879486083984375, 22.781871795654297, 21.23790740966797, 20.251558303833008, 19.459218978881836, 18.841686248779297, 18.15610694885254, 17.6778621673584, 16.85969352722168, 16.402873992919922, 16.042715072631836, 15.734576225280762, 15.461600303649902, 15.197709083557129, 14.934049606323242, 14.536728858947754, 14.310955047607422], 'root_mean_squared_error': [7.202741622924805, 4.773036003112793, 4.608460426330566, 4.500173091888428, 4.411260604858398, 4.340701580047607, 4.260998725891113, 4.204505443572998, 4.106055736541748, 4.050045967102051, 4.005335807800293, 3.9666833877563477, 3.932124137878418, 3.898423910140991, 3.864459753036499, 3.812706232070923, 3.782982349395752], 'val_loss': [28.778614044189453, 28.464153289794922, 27.6331844329834, 28.03975486755371, 22.809438705444336, 24.775758743286133, 23.00016212463379, 30.356029510498047, 19.540889739990234, 21.27634620666504, 21.39176368713379, 19.258563995361328, 20.626827239990234, 19.945207595825195, 20.082895278930664, 21.05435562133789, 19.713241577148438], 'val_root_mean_squared_error': [5.364570140838623, 5.335180759429932, 5.25672721862793, 5.295257568359375, 4.775922775268555, 4.977525234222412, 4.795848369598389, 5.5096306800842285, 4.420507907867432, 4.612628936767578, 4.625123023986816, 4.388457775115967, 4.5416765213012695, 4.466005802154541, 4.481394290924072, 4.588502407073975, 4.439959526062012], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025]}\n"
     ]
    }
   ],
   "source": [
    "for fold, (idx_tr, idx_va) in enumerate(kf.split(train_paths, groups=meta.donor)):\n",
    "    start_time = datetime.datetime.now()\n",
    "    model = None\n",
    "    gc.collect()\n",
    "\n",
    "    X_tr = train_paths[idx_tr]\n",
    "    y_tr = train_target[idx_tr]\n",
    "    X_va = train_paths[idx_va]\n",
    "    y_va = train_target[idx_va]\n",
    "    y_va_raw = Y[idx_va]\n",
    "\n",
    "\n",
    "    train_path_label_ds = tf.data.Dataset.from_tensor_slices((X_tr, y_tr))\n",
    "    train_image_label_ds = train_path_label_ds.map(load_and_preprocess_from_path_label,num_parallel_calls=tf.data.experimental.AUTOTUNE).shuffle(buffer_size=SHUFFLE_SIZE).repeat().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    val_path_label_ds = tf.data.Dataset.from_tensor_slices((X_va, y_va))\n",
    "    val_image_label_ds = val_path_label_ds.map(load_and_preprocess_from_path_label,num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, \n",
    "                           patience=3, verbose=VERBOSE)\n",
    "    es = EarlyStopping(monitor=\"val_loss\",\n",
    "                       patience=5, \n",
    "                       verbose=0,\n",
    "                       mode=\"min\", \n",
    "                       restore_best_weights=True)\n",
    "    ckpt = tf.keras.callbacks.ModelCheckpoint(f\"model/model_{fold}_ckpt\", save_best_only=True)\n",
    "    callbacks = [lr, es, ckpt]\n",
    "    # callbacks = [lr, es, tf.keras.callbacks.TerminateOnNaN()]\n",
    "\n",
    "    # Construct and compile the model\n",
    "    model = my_model()\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_image_label_ds, \n",
    "                        validation_data=val_image_label_ds, \n",
    "                        epochs=EPOCHS,\n",
    "                        steps_per_epoch=len(X_tr)//BATCH_SIZE,\n",
    "                        # verbose=VERBOSE,\n",
    "                        callbacks=callbacks)\n",
    "    # del X_tr, y_tr\n",
    "    \n",
    "    if SUBMIT:\n",
    "        model.save(f\"model/model_{fold}\")\n",
    "    history = history.history\n",
    "    histories.append(history)\n",
    "    callbacks, lr = None, None\n",
    "    \n",
    "    # We validate the model\n",
    "    y_va_pred = model.predict(tf.data.Dataset.from_tensor_slices(X_va).map(load_and_preprocess_from_path,num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE))\n",
    "    # corrscore = correlation_score(y_va, y_va_pred)\n",
    "    corrscore = correlation_score(y_va_raw.todense(), y_va_pred@pca2.components_)\n",
    "\n",
    "    print(f\"Fold {fold}: {es.stopped_epoch:3} epochs, corr =  {corrscore:.5f}\")\n",
    "    del es, X_va, X_tr#, y_va, y_va_pred\n",
    "    score_list.append(corrscore)\n",
    "\n",
    "# Show overall score\n",
    "print(f\"{Fore.GREEN}{Style.BRIGHT}Average  corr = {np.array(score_list).mean():.5f}{Style.RESET_ALL}\")\n",
    "\n",
    "#%%\n",
    "for hist in histories:\n",
    "    print(hist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a49a5",
   "metadata": {
    "papermill": {
     "duration": 0.009764,
     "end_time": "2022-10-02T05:34:42.428133",
     "exception": false,
     "start_time": "2022-10-02T05:34:42.418369",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction and submission\n",
    "\n",
    "We ensemble the test predictions of all Keras models. \n",
    "\n",
    "It has been pointed out in several discussion posts that the first 7476 rows of test (day 2, donor 27678) are identical to the first 7476 rows of train (day 2, donor 32606):\n",
    "- [CITEseq data: same RNA expression matrices from different donors in day2?](https://www.kaggle.com/competitions/open-problems-multimodal/discussion/349867) (@gwentea)\n",
    "-[Data contamination between CITEseq train/test datasets?](https://www.kaggle.com/competitions/open-problems-multimodal/discussion/349833) (@aglaros)\n",
    "- [Leak in public test set](https://www.kaggle.com/competitions/open-problems-multimodal/discussion/349867) (@psilogram)\n",
    "\n",
    "These rows belong to the public test set; the private leaderboard is not affected. We copy the 7476 rows from the training targets into the test predictions.\n",
    "\n",
    "At the end we concatenate the CITEseq predictions with @jsmithperera's predictions of the [Multiome Quickstart w/ Sparse M + tSVD = 32](https://www.kaggle.com/code/jsmithperera/multiome-quickstart-w-sparse-m-tsvd-32) notebook to get a complete submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a4d6423",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "#     image = tfio.experimental.image.decode_tiff(path)[...,:3]\n",
    "    image = tf.io.decode_png(image, channels=1, dtype=tf.dtypes.uint16)\n",
    "    image = tf.image.resize(image, size=(WIDTH,HEIGHT))\n",
    "    image = tf.broadcast_to(image, (image.shape[0], image.shape[1], 3))\n",
    "    image = tf.reshape(image, shape=[WIDTH,HEIGHT,3])\n",
    "\n",
    "    # image = tf.keras.applications.efficientnet.preprocess_input(image)\n",
    "    image = tf.keras.applications.efficientnet_v2.preprocess_input(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image)\n",
    "\n",
    "def load_and_preprocess_from_path(path):\n",
    "    return load_and_preprocess_image(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850d458",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3cb2d7e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with fold 0\n",
      "874/874 [==============================] - 80s 91ms/step\n",
      "Predicting with fold 1\n",
      "874/874 [==============================] - 81s 92ms/step\n",
      "Predicting with fold 2\n",
      "874/874 [==============================] - 79s 89ms/step\n"
     ]
    }
   ],
   "source": [
    "test_paths = TEST_BASEPATH + cell_index_test + \".png\"\n",
    "preds = np.zeros((len(test_paths), 23418), dtype='float16')\n",
    "test_path_ds = tf.data.Dataset.from_tensor_slices(test_paths)\n",
    "test_image_ds = test_path_ds.map(load_and_preprocess_from_path, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "for fold in range(N_SPLITS):\n",
    "    print(f\"Predicting with fold {fold}\")\n",
    "\n",
    "    model = load_model(f\"model/model_{fold}\")\n",
    "    preds += (model.predict(test_image_ds)@pca2.components_)/N_SPLITS\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "201285f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T05:34:42.449196Z",
     "iopub.status.busy": "2022-10-02T05:34:42.448790Z",
     "iopub.status.idle": "2022-10-02T05:38:27.712103Z",
     "shell.execute_reply": "2022-10-02T05:38:27.710711Z"
    },
    "papermill": {
     "duration": 225.28903,
     "end_time": "2022-10-02T05:38:27.726803",
     "exception": false,
     "start_time": "2022-10-02T05:34:42.437773",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# n=1\n",
    "# d = len(test_paths)//n\n",
    "\n",
    "# preds = np.zeros((len(test_paths), 23418), dtype='float16')\n",
    "# for i,xx in enumerate(test_paths):\n",
    "#     for fold in range(N_SPLITS):\n",
    "#         print(f\"Predicting with fold {fold}\")\n",
    "#         train_path_label_ds = tf.data.Dataset.from_tensor_slices(xx)\n",
    "#         train_image_label_ds = train_path_label_ds.map(load_and_preprocess_from_path, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "#         model = load_model(f\"model/model_{fold}\")\n",
    "#         preds[i*d:i*d+d,:] += (model.predict(xx)@pca2.components_)/N_SPLITS\n",
    "#         gc.collect()\n",
    "#     print('')\n",
    "#     del xx\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7746d761",
   "metadata": {
    "papermill": {
     "duration": 0.014067,
     "end_time": "2022-10-02T05:38:27.753901",
     "exception": false,
     "start_time": "2022-10-02T05:38:27.739834",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Read the table of rows and columns required for submission\n",
    "eval_ids = pd.read_parquet(\"C:/Users/Owner/Documents/dev/open-problem/multimodal-single-cell-as-sparse-matrix/evaluation.parquet\")\n",
    "# Convert the string columns to more efficient categorical types\n",
    "#eval_ids.cell_id = eval_ids.cell_id.apply(lambda s: int(s, base=16))\n",
    "eval_ids.cell_id = eval_ids.cell_id.astype(pd.CategoricalDtype())\n",
    "eval_ids.gene_id = eval_ids.gene_id.astype(pd.CategoricalDtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "32a65422",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id    cell_id       gene_id        \n",
       "0         c2150f55becb  CD86              NaN\n",
       "1         c2150f55becb  CD274             NaN\n",
       "2         c2150f55becb  CD270             NaN\n",
       "3         c2150f55becb  CD155             NaN\n",
       "4         c2150f55becb  CD112             NaN\n",
       "                                           ..\n",
       "65744175  2c53aa67933d  ENSG00000134419   NaN\n",
       "65744176  2c53aa67933d  ENSG00000186862   NaN\n",
       "65744177  2c53aa67933d  ENSG00000170959   NaN\n",
       "65744178  2c53aa67933d  ENSG00000107874   NaN\n",
       "65744179  2c53aa67933d  ENSG00000166012   NaN\n",
       "Name: target, Length: 65744180, dtype: float32"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare an empty series which will be filled with predictions\n",
    "submission = pd.Series(name='target',\n",
    "                       index=pd.MultiIndex.from_frame(eval_ids), \n",
    "                       dtype=np.float32)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e916ea54",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "np.save('preds.npy', preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d0b0914",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 250 ms\n",
      "Wall time: 221 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_columns = np.load(\"C:/Users/Owner/Documents/dev/open-problem/multimodal-single-cell-as-sparse-matrix/train_multi_targets_idxcol.npz\",\n",
    "                   allow_pickle=True)[\"columns\"]\n",
    "\n",
    "test_index = np.load(\"C:/Users/Owner/Documents/dev/open-problem/multimodal-single-cell-as-sparse-matrix/test_multi_inputs_idxcol.npz\",\n",
    "                    allow_pickle=True)[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "98ef47be",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "cell_dict = dict((k,v) for v,k in enumerate(test_index)) \n",
    "assert len(cell_dict)  == len(test_index)\n",
    "\n",
    "gene_dict = dict((k,v) for v,k in enumerate(y_columns))\n",
    "assert len(gene_dict) == len(y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6dc9feb0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "eval_ids_cell_num = eval_ids.cell_id.apply(lambda x:cell_dict.get(x, -1))\n",
    "eval_ids_gene_num = eval_ids.gene_id.apply(lambda x:gene_dict.get(x, -1))\n",
    "\n",
    "valid_multi_rows = (eval_ids_gene_num !=-1) & (eval_ids_cell_num!=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d42506b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bf0c68c4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "submission.iloc[valid_multi_rows] = preds[eval_ids_cell_num[valid_multi_rows].to_numpy(),\n",
    "eval_ids_gene_num[valid_multi_rows].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fa9a6a4f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del eval_ids_cell_num, eval_ids_gene_num, valid_multi_rows, eval_ids, test_index, y_columns\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5bfe3a99",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id    cell_id       gene_id        \n",
       "0         c2150f55becb  CD86                    NaN\n",
       "1         c2150f55becb  CD274                   NaN\n",
       "2         c2150f55becb  CD270                   NaN\n",
       "3         c2150f55becb  CD155                   NaN\n",
       "4         c2150f55becb  CD112                   NaN\n",
       "                                             ...   \n",
       "65744175  2c53aa67933d  ENSG00000134419    5.566406\n",
       "65744176  2c53aa67933d  ENSG00000186862    0.036133\n",
       "65744177  2c53aa67933d  ENSG00000170959    0.044006\n",
       "65744178  2c53aa67933d  ENSG00000107874    0.948242\n",
       "65744179  2c53aa67933d  ENSG00000166012    4.929688\n",
       "Name: target, Length: 65744180, dtype: float32"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5614c3f7",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "submission.reset_index(drop=True, inplace=True)\n",
    "submission.index.name = 'row_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5158364f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "cite_submission = pd.read_csv(\"C:/Users/Owner/Documents/dev/open-problem/citeseq/submission_svd256_wdo.csv\")\n",
    "cite_submission = cite_submission.set_index(\"row_id\")\n",
    "cite_submission = cite_submission[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5b75dbc7",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "submission[submission.isnull()] = cite_submission[submission.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "56556832",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cfd6a11f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv(submission_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1199.922254,
   "end_time": "2022-10-02T05:38:31.131213",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-02T05:18:31.208959",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "0dc5be61c8cf786c9afde4d6369564156d9ad36efd591152a3b3e204603eb87a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

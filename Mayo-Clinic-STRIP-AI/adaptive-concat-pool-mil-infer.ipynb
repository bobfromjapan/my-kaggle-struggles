{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81108c7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:10:24.331996Z",
     "iopub.status.busy": "2022-09-18T06:10:24.331311Z",
     "iopub.status.idle": "2022-09-18T06:10:24.340977Z",
     "shell.execute_reply": "2022-09-18T06:10:24.340184Z"
    },
    "papermill": {
     "duration": 0.019387,
     "end_time": "2022-09-18T06:10:24.343071",
     "exception": false,
     "start_time": "2022-09-18T06:10:24.323684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db83f44d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:10:24.353465Z",
     "iopub.status.busy": "2022-09-18T06:10:24.353184Z",
     "iopub.status.idle": "2022-09-18T06:10:56.655268Z",
     "shell.execute_reply": "2022-09-18T06:10:56.654177Z"
    },
    "papermill": {
     "duration": 32.310413,
     "end_time": "2022-09-18T06:10:56.658215",
     "exception": false,
     "start_time": "2022-09-18T06:10:24.347802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "######################################################################## | 100% \r\n",
      "######################################################################## | 100% \r\n",
      "######################################################################## | 100% \r\n",
      "######################################################################## | 100% \r\n",
      "######################################################################## | 100% \r\n",
      "######################################################################## | 100% \r\n",
      "######################################################################## | 100% \r\n",
      "######################################################################## | 100% \r\n",
      "######################################################################## | 100% \r\n",
      "######################################################################## | 100% \r\n",
      "######################################################################## | 100% \r\n",
      "######################################################################## | 100% \r\n",
      "######################################################################## | 100% \r\n",
      "######################################################################## | 100% \r\n",
      "######################################################################## | 100% \r\n",
      "######################################################################## | 100% \r\n",
      "######################################################################## | 100% \r\n",
      "######################################################################## | 100% \r\n",
      "######################################################################## | 100% \r\n",
      "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\r\n",
      "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\r\n",
      "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\r\n"
     ]
    }
   ],
   "source": [
    "# !conda install -y --channel conda-forge pyvips\n",
    "!conda install ../input/pyvips-install/pyvips/*.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1db68a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:10:56.676527Z",
     "iopub.status.busy": "2022-09-18T06:10:56.676189Z",
     "iopub.status.idle": "2022-09-18T06:10:57.002240Z",
     "shell.execute_reply": "2022-09-18T06:10:57.001335Z"
    },
    "papermill": {
     "duration": 0.337839,
     "end_time": "2022-09-18T06:10:57.004639",
     "exception": false,
     "start_time": "2022-09-18T06:10:56.666800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from openslide import OpenSlide\n",
    "import tifffile as tiff\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04007936",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:10:57.023109Z",
     "iopub.status.busy": "2022-09-18T06:10:57.022365Z",
     "iopub.status.idle": "2022-09-18T06:10:57.030609Z",
     "shell.execute_reply": "2022-09-18T06:10:57.029805Z"
    },
    "papermill": {
     "duration": 0.0192,
     "end_time": "2022-09-18T06:10:57.032358",
     "exception": false,
     "start_time": "2022-09-18T06:10:57.013158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# test_image_paths = glob.glob(\"../input/mayo-clinic-strip-ai/train/*.tif\")\n",
    "test_image_paths = glob.glob(\"../input/mayo-clinic-strip-ai/test/*.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edcbb928",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:10:57.049695Z",
     "iopub.status.busy": "2022-09-18T06:10:57.049443Z",
     "iopub.status.idle": "2022-09-18T06:10:57.053459Z",
     "shell.execute_reply": "2022-09-18T06:10:57.052564Z"
    },
    "papermill": {
     "duration": 0.0147,
     "end_time": "2022-09-18T06:10:57.055205",
     "exception": false,
     "start_time": "2022-09-18T06:10:57.040505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scale = 4\n",
    "# output_dir = \"/kaggle/working/\"\n",
    "# too_big_for_process = []\n",
    "# # for path in test_image_paths[180:200]:\n",
    "# for path in test_image_paths:\n",
    "\n",
    "#     print(path)\n",
    "#     slide = OpenSlide(path)\n",
    "\n",
    "#     if slide.dimensions[0]*slide.dimensions[1] < 4131662535:\n",
    "#         image_id = os.path.splitext(os.path.basename(path))[0]\n",
    "#         image = tiff.imread(path)\n",
    "#         print(f\"{image.shape}\")\n",
    "#         cv2.imwrite(os.path.join(output_dir, f\"{image_id}.jpg\"), image[::scale,::scale,::-1])\n",
    "#         del image\n",
    "#         gc.collect()\n",
    "#     else:\n",
    "#         print(\"Skip process for avoiding OOM possibility.\")\n",
    "#         too_big_for_process.append(path)\n",
    "\n",
    "# test_image_paths = glob.glob(\"/kaggle/working/*.jpg\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0cc9491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:10:57.073645Z",
     "iopub.status.busy": "2022-09-18T06:10:57.072240Z",
     "iopub.status.idle": "2022-09-18T06:11:00.876174Z",
     "shell.execute_reply": "2022-09-18T06:11:00.875120Z"
    },
    "papermill": {
     "duration": 3.815334,
     "end_time": "2022-09-18T06:11:00.878764",
     "exception": false,
     "start_time": "2022-09-18T06:10:57.063430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "# from efficientnet_pytorch import EfficientNet\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import torchvision\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "import pyvips\n",
    "import scipy.stats\n",
    "import random\n",
    "from fastai.vision import *\n",
    "from fastai.layers import AdaptiveConcatPool2d, Flatten, Mish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64bc5dc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:11:00.898242Z",
     "iopub.status.busy": "2022-09-18T06:11:00.897357Z",
     "iopub.status.idle": "2022-09-18T06:11:00.907435Z",
     "shell.execute_reply": "2022-09-18T06:11:00.906541Z"
    },
    "papermill": {
     "duration": 0.022243,
     "end_time": "2022-09-18T06:11:00.909335",
     "exception": false,
     "start_time": "2022-09-18T06:11:00.887092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, arch='tf_efficientnetv2_s', n=1, pre=False):\n",
    "        super().__init__()\n",
    "#         m = torch.hub.load('../input/facebookresearchsemisupervisedimagenet1kmodels/semi-supervised-ImageNet1K-models-master', model=arch, source='local')\n",
    "        m = timm.create_model(arch, pretrained=False)\n",
    "        self.enc = nn.Sequential(*list(m.children())[:-2])       \n",
    "        nc = list(m.children())[-1].in_features\n",
    "        self.head = nn.Sequential(AdaptiveConcatPool2d(),Flatten(),nn.Linear(2*nc,512),\n",
    "                            Mish(),nn.BatchNorm1d(512), nn.Dropout(0.5),nn.Linear(512,n))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = [x for x in x]\n",
    "        shape = x[0].shape\n",
    "        n = 16\n",
    "        x = torch.stack(x,1).view(-1,shape[1],shape[2],shape[3])\n",
    "        #x: bs*N x 3 x 128 x 128\n",
    "        x = self.enc(x)\n",
    "        #x: bs*N x C x 4 x 4\n",
    "        shape = x.shape\n",
    "        #concatenate the output for tiles into a single map\n",
    "        x = x.view(-1,n,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous()\\\n",
    "          .view(-1,shape[1],shape[2]*n,shape[3])\n",
    "        #x: bs x C x N*4 x 4\n",
    "        x = self.head(x)\n",
    "        #x: bs x n\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "136c45fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:11:00.926372Z",
     "iopub.status.busy": "2022-09-18T06:11:00.926083Z",
     "iopub.status.idle": "2022-09-18T06:11:00.934397Z",
     "shell.execute_reply": "2022-09-18T06:11:00.933535Z"
    },
    "papermill": {
     "duration": 0.019051,
     "end_time": "2022-09-18T06:11:00.936315",
     "exception": false,
     "start_time": "2022-09-18T06:11:00.917264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "    def __init__(self, arch='swinv2_tiny_window16_256', n=1, pre=False):\n",
    "        super().__init__()\n",
    "#         m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', arch)\n",
    "        m = timm.create_model(arch, pretrained=pre, num_classes=0)\n",
    "        self.enc = m\n",
    "#         nc = list(m.children())[-1].in_features\n",
    "        self.nc=768\n",
    "        self.head = nn.Sequential(AdaptiveConcatPool2d(),Flatten(),nn.Linear(2*self.nc,512),\n",
    "                            Mish(),nn.BatchNorm1d(512), nn.Dropout(0.5),nn.Linear(512,n))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = [x for x in x]\n",
    "        shape = x[0].shape\n",
    "        n = N\n",
    "        x = torch.stack(x,1).view(-1,shape[1],shape[2],shape[3])\n",
    "        #x: bs*N x 3 x 128 x 128\n",
    "        x = self.enc(x)\n",
    "        #x: bs*N x C x 4 x 4\n",
    "        shape = x.shape\n",
    "#         print(x.shape)\n",
    "        #concatenate the output for tiles into a single map\n",
    "        x =  x.view(-1, 16, self.nc, 1).permute(0,2,1,3).contiguous() # 1024 for swinv2_base_window16_256, 768 for swinv2_tiny_window8_256, 192 for vit_tiny_patch16_384, 384 for vit_small, deit3_small_patch16_384_in21ft1k\n",
    "        #x: bs x C x N*4 x 4\n",
    "        x = self.head(x)\n",
    "        #x: bs x n\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9f01f4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:11:00.953794Z",
     "iopub.status.busy": "2022-09-18T06:11:00.952975Z",
     "iopub.status.idle": "2022-09-18T06:11:01.009816Z",
     "shell.execute_reply": "2022-09-18T06:11:01.008950Z"
    },
    "papermill": {
     "duration": 0.067359,
     "end_time": "2022-09-18T06:11:01.011635",
     "exception": false,
     "start_time": "2022-09-18T06:11:00.944276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "tile_sz=384\n",
    "sz = 384\n",
    "sz2 = 256\n",
    "N=64\n",
    "ims_per_batch = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52343779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:11:01.029935Z",
     "iopub.status.busy": "2022-09-18T06:11:01.028550Z",
     "iopub.status.idle": "2022-09-18T06:11:04.503173Z",
     "shell.execute_reply": "2022-09-18T06:11:04.502096Z"
    },
    "papermill": {
     "duration": 3.485901,
     "end_time": "2022-09-18T06:11:04.505608",
     "exception": false,
     "start_time": "2022-09-18T06:11:01.019707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/mayo-concat-tile-pooling/models/concat-tile-pooling-128-fold2.pth',\n",
       " '../input/mayo-concat-tile-pooling/models/concat-tile-pooling-128-fold1.pth',\n",
       " '../input/mayo-concat-tile-pooling/models/concat-tile-pooling-128-fold3.pth',\n",
       " '../input/mayo-concat-tile-pooling/models/concat-tile-pooling-128-fold0.pth']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_class = 2\n",
    "# backbone = timm.create_model(model_name, pretrained=False, num_classes=0).to(device)\n",
    "# model = nn.Sequential(\n",
    "#     backbone,\n",
    "#     nn.Dropout(0.2),\n",
    "#     nn.Linear(backbone.num_features, n_class)\n",
    "# ).to(device)\n",
    "\n",
    "model = Model().to(device)\n",
    "\n",
    "# model_path = \"../input/mayoinfermodelbfjctp/20220821_models/kaggle/working/models/*.pth\"\n",
    "model_path = \"../input/mayo-concat-tile-pooling/models/*.pth\"\n",
    "model_paths = glob.glob(model_path)\n",
    "\n",
    "model_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d0ef53d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:11:04.526564Z",
     "iopub.status.busy": "2022-09-18T06:11:04.526194Z",
     "iopub.status.idle": "2022-09-18T06:11:05.183019Z",
     "shell.execute_reply": "2022-09-18T06:11:05.181996Z"
    },
    "papermill": {
     "duration": 0.669744,
     "end_time": "2022-09-18T06:11:05.185303",
     "exception": false,
     "start_time": "2022-09-18T06:11:04.515559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:2227.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../input/mayo-concat-tile-pooling-transformer/models/concat-tile-pooling-256-swinv2-fold1.pth',\n",
       " '../input/mayo-concat-tile-pooling-transformer/models/concat-tile-pooling-256-swinv2-fold2.pth',\n",
       " '../input/mayo-concat-tile-pooling-transformer/models/concat-tile-pooling-256-swinv2-fold4.pth',\n",
       " '../input/mayo-concat-tile-pooling-transformer/models/concat-tile-pooling-256-swinv2-fold0.pth',\n",
       " '../input/mayo-concat-tile-pooling-transformer/models/concat-tile-pooling-256-swinv2-fold3.pth']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Model2().to(device)\n",
    "model2_path = \"../input/mayo-concat-tile-pooling-transformer/models/*.pth\"\n",
    "model2_paths = glob.glob(model2_path)\n",
    "\n",
    "model2_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7d08a5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:11:05.203892Z",
     "iopub.status.busy": "2022-09-18T06:11:05.203579Z",
     "iopub.status.idle": "2022-09-18T06:11:05.224379Z",
     "shell.execute_reply": "2022-09-18T06:11:05.223561Z"
    },
    "papermill": {
     "duration": 0.032248,
     "end_time": "2022-09-18T06:11:05.226368",
     "exception": false,
     "start_time": "2022-09-18T06:11:05.194120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tile(img, sz=128, N=64):\n",
    "    shape = img.shape\n",
    "    pad0,pad1 = (sz - shape[0]%sz)%sz, (sz - shape[1]%sz)%sz\n",
    "    img = np.pad(img,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],constant_values=255)\n",
    "    img = img.reshape(img.shape[0]//sz,sz,img.shape[1]//sz,sz,3)\n",
    "    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n",
    "    if len(img) < N:\n",
    "        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n",
    "    scores = []\n",
    "    for im in img:\n",
    "        scores.append(len(cv2.imencode(\".jpg\", im)[1]))\n",
    "#     idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n",
    "#     img = img[idxs]\n",
    "    scores, img = zip(*sorted(zip(scores, img), reverse=True, key=lambda x: x[0]))\n",
    "    high_info_ind = pd.Series(scores).where(pd.Series(scores) > 30000).idxmin()\n",
    "#     print(high_info_ind is not np.nan)\n",
    "    \n",
    "    bg_ind = pd.Series(scores).where(pd.Series(scores) > 10000).idxmin()\n",
    "    bg_cand = img[bg_ind:]\n",
    "    for bgi, bg in enumerate(bg_cand):\n",
    "        bg = bg.reshape(bg.shape[0] * bg.shape[1], bg.shape[2])\n",
    "        white, _ = scipy.stats.mode(bg, axis=0)\n",
    "        diff_to_white = (255,255,255) - white\n",
    "        if sum(diff_to_white[0]) < 128*3:\n",
    "            break\n",
    "        else:\n",
    "            diff_to_white = [[0,0,0]]\n",
    "    \n",
    "    if high_info_ind < N or high_info_ind is np.nan:\n",
    "        return img[:N], bg_cand[bgi], diff_to_white\n",
    "    else:\n",
    "        high_info_indexes = random.sample(list(range(high_info_ind)), N)\n",
    "        img2 = []\n",
    "        for i in high_info_indexes:\n",
    "            img2.append(img[i])\n",
    "        return img2, bg_cand[bgi], diff_to_white\n",
    "\n",
    "def vips2numpy(vi):\n",
    "    format_to_dtype = {\n",
    "       'uchar': np.uint8,\n",
    "       'char': np.int8,\n",
    "       'ushort': np.uint16,\n",
    "       'short': np.int16,\n",
    "       'uint': np.uint32,\n",
    "       'int': np.int32,\n",
    "       'float': np.float32,\n",
    "       'double': np.float64,\n",
    "       'complex': np.complex64,\n",
    "       'dpcomplex': np.complex128,\n",
    "    }\n",
    "    return np.ndarray(buffer=vi.write_to_memory(),dtype=format_to_dtype[vi.format],shape=[vi.height, vi.width, vi.bands])\n",
    "\n",
    "def return_tiled_images(image_path, transform, N=64, ims_per_batch=16 ,max_size=20000, crop_size=384):\n",
    "    image = pyvips.Image.thumbnail(image_path, max_size)\n",
    "    image = vips2numpy(image)\n",
    "    width, height, c = image.shape\n",
    "    print(f\"Input width: {width} height: {height}\")\n",
    "    images, bg, diff_to_white = tile(image, sz=crop_size, N=N)\n",
    "    output_images = []\n",
    "    for idx, img in enumerate(images):\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "#         img = cv2.imencode(\".jpg\", img, [cv2.IMWRITE_JPEG_QUALITY, 100])[1]\n",
    "#         img = cv2.imdecode(img, flags=cv2.IMREAD_COLOR)\n",
    "        img = img + diff_to_white\n",
    "        img = img / img.max()\n",
    "        img = np.clip(img * 255, a_min = 0, a_max = 255).astype(np.uint8)\n",
    "        img = transform(img)\n",
    "        \n",
    "        output_images.append(img)\n",
    "    \n",
    "    img_indexes = random.sample(list(range(0, N)), N)\n",
    "    \n",
    "    batched_images = []\n",
    "    one_batch = []\n",
    "    for i, index in enumerate(img_indexes):\n",
    "        one_batch.append(output_images[index])\n",
    "        if i%ims_per_batch==(ims_per_batch-1):\n",
    "            batched_images.append(torch.stack(one_batch, dim=0))\n",
    "            one_batch = []\n",
    "\n",
    "    batched_images = torch.stack(batched_images, dim=0)\n",
    "#     del img, image, images, output_images; gc.collect()\n",
    "    return batched_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "940f73cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:11:05.244589Z",
     "iopub.status.busy": "2022-09-18T06:11:05.244315Z",
     "iopub.status.idle": "2022-09-18T06:13:07.450157Z",
     "shell.execute_reply": "2022-09-18T06:13:07.449178Z"
    },
    "papermill": {
     "duration": 122.218022,
     "end_time": "2022-09-18T06:13:07.452758",
     "exception": false,
     "start_time": "2022-09-18T06:11:05.234736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input width: 20000 height: 11187\n",
      "Input width: 20000 height: 4937\n",
      "Input width: 20000 height: 4005\n",
      "Input width: 9512 height: 20000\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.Resize((sz, sz)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "preds = []\n",
    "\n",
    "for path in test_image_paths:\n",
    "    images = return_tiled_images(image_path=path, transform=transform, N=N, max_size=20000, crop_size=tile_sz)\n",
    "    images2 = []\n",
    "    for batch in images:\n",
    "        images2.append(torchvision.transforms.Resize((sz2, sz2))(batch))\n",
    "        \n",
    "    images2 = torch.stack(images2, dim=0)\n",
    "    images = images.to(device)\n",
    "    images2 = images2.to(device)\n",
    "\n",
    "    \n",
    "    for i, m_path in enumerate(model_paths):\n",
    "        model.load_state_dict(\n",
    "        torch.load(\n",
    "            m_path, map_location=device\n",
    "            )\n",
    "        )\n",
    "        model.train(False)\n",
    "        with torch.cuda.amp.autocast():\n",
    "#             pred = model(torch.unsqueeze(images, 0))\n",
    "            pred = model(images)\n",
    "\n",
    "        pred = torch.sigmoid(pred).to('cpu').detach().numpy().copy()\n",
    "\n",
    "        pred_ce = ((1 - pred)**2).mean()\n",
    "        pred_laa = (pred**2).mean()\n",
    "\n",
    "        preds.append((path, i, \"model1\", pred_ce, pred_laa))\n",
    "\n",
    "    for i, m_path in enumerate(model2_paths):\n",
    "        model2.load_state_dict(\n",
    "        torch.load(\n",
    "            m_path, map_location=device\n",
    "            )\n",
    "        )\n",
    "        model2.train(False)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "#             pred = model(torch.unsqueeze(images, 0))\n",
    "            pred2 = model2(images2)\n",
    "    \n",
    "        pred2 = torch.sigmoid(pred2).to('cpu').detach().numpy().copy()\n",
    "#         print(pred2)\n",
    "\n",
    "        pred2_ce = ((1 - pred2)**2).mean()\n",
    "        pred2_laa = (pred2**2).mean()\n",
    "\n",
    "        preds.append((path, i, \"model2\", pred2_ce, pred2_laa))\n",
    "\n",
    "        \n",
    "    del images, images2\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db3aa3db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:13:07.472134Z",
     "iopub.status.busy": "2022-09-18T06:13:07.471837Z",
     "iopub.status.idle": "2022-09-18T06:13:07.477161Z",
     "shell.execute_reply": "2022-09-18T06:13:07.476335Z"
    },
    "papermill": {
     "duration": 0.017332,
     "end_time": "2022-09-18T06:13:07.479203",
     "exception": false,
     "start_time": "2022-09-18T06:13:07.461871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if len(too_big_for_process)>0:\n",
    "#     for i in too_big_for_process:\n",
    "#         preds.append((i, 0, 0.82, 0.28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a62f60ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:13:07.499306Z",
     "iopub.status.busy": "2022-09-18T06:13:07.498937Z",
     "iopub.status.idle": "2022-09-18T06:13:07.503206Z",
     "shell.execute_reply": "2022-09-18T06:13:07.501998Z"
    },
    "papermill": {
     "duration": 0.015832,
     "end_time": "2022-09-18T06:13:07.505315",
     "exception": false,
     "start_time": "2022-09-18T06:13:07.489483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# images = return_tiled_images(image_path=path, transform=transform, N=N, max_size=20000, crop_size=tile_sz)\n",
    "# images2 = []\n",
    "# for batch in images:\n",
    "#     images2.append(torchvision.transforms.Resize((sz2, sz2))(batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4386913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:13:07.524418Z",
     "iopub.status.busy": "2022-09-18T06:13:07.524138Z",
     "iopub.status.idle": "2022-09-18T06:13:07.527910Z",
     "shell.execute_reply": "2022-09-18T06:13:07.526966Z"
    },
    "papermill": {
     "duration": 0.015228,
     "end_time": "2022-09-18T06:13:07.529922",
     "exception": false,
     "start_time": "2022-09-18T06:13:07.514694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_data = torch.zeros([4, 16, 3, 256, 256], dtype=torch.float16).to(device)\n",
    "# with torch.cuda.amp.autocast():\n",
    "#     t = model2(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20935970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:13:07.548048Z",
     "iopub.status.busy": "2022-09-18T06:13:07.547786Z",
     "iopub.status.idle": "2022-09-18T06:13:07.552812Z",
     "shell.execute_reply": "2022-09-18T06:13:07.552030Z"
    },
    "papermill": {
     "duration": 0.016239,
     "end_time": "2022-09-18T06:13:07.554701",
     "exception": false,
     "start_time": "2022-09-18T06:13:07.538462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ada1040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:13:07.572857Z",
     "iopub.status.busy": "2022-09-18T06:13:07.572600Z",
     "iopub.status.idle": "2022-09-18T06:13:07.584381Z",
     "shell.execute_reply": "2022-09-18T06:13:07.583457Z"
    },
    "papermill": {
     "duration": 0.022948,
     "end_time": "2022-09-18T06:13:07.586265",
     "exception": false,
     "start_time": "2022-09-18T06:13:07.563317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def path_to_patient_id(path):\n",
    "    return os.path.basename(path).split(\"_\")[0]\n",
    "\n",
    "df = pd.DataFrame(preds, columns=(\"path\", \"fold\", \"model\", \"CE\", \"LAA\"))\n",
    "df[\"patient_id\"] = df[\"path\"].map(path_to_patient_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbcb22b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:13:07.604763Z",
     "iopub.status.busy": "2022-09-18T06:13:07.604507Z",
     "iopub.status.idle": "2022-09-18T06:13:07.608327Z",
     "shell.execute_reply": "2022-09-18T06:13:07.607345Z"
    },
    "papermill": {
     "duration": 0.015629,
     "end_time": "2022-09-18T06:13:07.610618",
     "exception": false,
     "start_time": "2022-09-18T06:13:07.594989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d01ea8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:13:07.628704Z",
     "iopub.status.busy": "2022-09-18T06:13:07.628449Z",
     "iopub.status.idle": "2022-09-18T06:13:07.641716Z",
     "shell.execute_reply": "2022-09-18T06:13:07.640904Z"
    },
    "papermill": {
     "duration": 0.024568,
     "end_time": "2022-09-18T06:13:07.643730",
     "exception": false,
     "start_time": "2022-09-18T06:13:07.619162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.groupby(\"patient_id\").mean().drop(\"fold\", axis=1).to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79c3f541",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T06:13:07.662201Z",
     "iopub.status.busy": "2022-09-18T06:13:07.661944Z",
     "iopub.status.idle": "2022-09-18T06:13:07.676871Z",
     "shell.execute_reply": "2022-09-18T06:13:07.675943Z"
    },
    "papermill": {
     "duration": 0.026282,
     "end_time": "2022-09-18T06:13:07.678834",
     "exception": false,
     "start_time": "2022-09-18T06:13:07.652552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CE</th>\n",
       "      <th>LAA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>006388</th>\n",
       "      <td>0.416504</td>\n",
       "      <td>0.252441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>008e5c</th>\n",
       "      <td>0.485352</td>\n",
       "      <td>0.201294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00c058</th>\n",
       "      <td>0.461914</td>\n",
       "      <td>0.192383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01adc5</th>\n",
       "      <td>0.486816</td>\n",
       "      <td>0.123596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CE       LAA\n",
       "patient_id                    \n",
       "006388      0.416504  0.252441\n",
       "008e5c      0.485352  0.201294\n",
       "00c058      0.461914  0.192383\n",
       "01adc5      0.486816  0.123596"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"patient_id\").mean().drop(\"fold\", axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 173.253041,
   "end_time": "2022-09-18T06:13:10.194440",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-18T06:10:16.941399",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
